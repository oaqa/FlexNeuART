{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the repo is cloned, all necessary packages are installed, including calling the script:\n",
    "\n",
    "```./install_packages.sh```\n",
    "\n",
    "and the code is compiled:\n",
    "\n",
    "```./build.sh```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing directory to the repo root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/FlexNeuART\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading demo data\n",
    "\n",
    "1. Download [this file from our Google Drive](https://drive.google.com/file/d/1mDa6J4hNYPyqlS8hVi6bykSbAOMKsDwe/view?usp=sharing) and copy it to the source root directory, where it should be unpacked. As a result, a source directory should contain a sub-directory ``collections/msmarco_doc``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: statistics on downloaded data should look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "Checking data sub-directory: bitext\n",
      "Checking data sub-directory: dev\n",
      "Checking data sub-directory: dev_official\n",
      "Checking data sub-directory: docs\n",
      "Found indexable data file: docs/AnswerFields.jsonl.gz\n",
      "Checking data sub-directory: test2019\n",
      "Checking data sub-directory: test2020\n",
      "Checking data sub-directory: train_fusion\n",
      "Found query file: bitext/QuestionFields.jsonl\n",
      "Found query file: dev/QuestionFields.jsonl\n",
      "Found query file: dev_official/QuestionFields.jsonl\n",
      "Found query file: test2019/QuestionFields.jsonl\n",
      "Found query file: test2020/QuestionFields.jsonl\n",
      "Found query file: train_fusion/QuestionFields.jsonl\n",
      "getIndexQueryDataInfo return value:  docs AnswerFields.jsonl.gz ,bitext,dev,dev_official,test2019,test2020,train_fusion QuestionFields.jsonl\n",
      "Using the data input files: AnswerFields.jsonl.gz, QuestionFields.jsonl\n",
      "Index dirs: docs\n",
      "Query dirs:  bitext dev dev_official test2019 test2020 train_fusion\n",
      "Queries/questions:\n",
      "bitext 352013\n",
      "dev 5000\n",
      "dev_official 5193\n",
      "test2019 43\n",
      "test2020 45\n",
      "train_fusion 10000\n",
      "Documents/passages/answers:\n",
      "docs 3213802\n"
     ]
    }
   ],
   "source": [
    "!scripts/report/get_basic_collect_stat.sh msmarco_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing (each step takes a few hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lucene index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "==========================================================================\n",
      "Data directory: collections/msmarco_doc/input_data\n",
      "Index directory: collections/msmarco_doc/lucene_index\n",
      "Removing previously created index (if exists)\n",
      "==========================================================================\n",
      "Checking data sub-directory: bitext\n",
      "Checking data sub-directory: dev\n",
      "Checking data sub-directory: dev_official\n",
      "Checking data sub-directory: docs\n",
      "Found indexable data file: docs/AnswerFields.jsonl.gz\n",
      "Checking data sub-directory: test2019\n",
      "Checking data sub-directory: test2020\n",
      "Checking data sub-directory: train_fusion\n",
      "Found query file: bitext/QuestionFields.jsonl\n",
      "Found query file: dev/QuestionFields.jsonl\n",
      "Found query file: dev_official/QuestionFields.jsonl\n",
      "Found query file: test2019/QuestionFields.jsonl\n",
      "Found query file: test2020/QuestionFields.jsonl\n",
      "Found query file: train_fusion/QuestionFields.jsonl\n",
      "Using the data input file: AnswerFields.jsonl.gz\n",
      "JAVA_OPTS=-Xms8388608k -Xmx14680064k -server\n",
      "Creating a new Lucene index, maximum # of docs to process: 2147483647\n",
      "Input file name: collections/msmarco_doc/input_data/docs/AnswerFields.jsonl.gz\n",
      "Indexed 10000 docs\n",
      "Indexed 20000 docs\n",
      "Indexed 30000 docs\n",
      "Indexed 40000 docs\n",
      "Indexed 50000 docs\n",
      "Committing\n",
      "...\n",
      "Indexed 3070000 docs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 3080000 docs\n",
      "Indexed 3090000 docs\n",
      "Indexed 3100000 docs\n",
      "Committing\n",
      "Indexed 3110000 docs\n",
      "Indexed 3120000 docs\n",
      "Indexed 3130000 docs\n",
      "Indexed 3140000 docs\n",
      "Indexed 3150000 docs\n",
      "Committing\n",
      "Indexed 3160000 docs\n",
      "Indexed 3170000 docs\n",
      "Indexed 3180000 docs\n",
      "Indexed 3190000 docs\n",
      "Indexed 3200000 docs\n",
      "Committing\n",
      "Indexed 3210000 docs\n",
      "Indexed 3213802 docs\n"
     ]
    }
   ],
   "source": [
    "!scripts/index/create_lucene_index.sh msmarco_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward indices (text is not really necessary for this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "==========================================================================\n",
      "Data directory:            collections/msmarco_doc/input_data\n",
      "Forward index directory:   collections/msmarco_doc/forward_index/\n",
      "Clean old index?:          0\n",
      "Field list definition:     text:parsedText text_raw:raw\n",
      "==========================================================================\n",
      "Checking data sub-directory: bitext\n",
      "Checking data sub-directory: dev\n",
      "Checking data sub-directory: dev_official\n",
      "Checking data sub-directory: docs\n",
      "Found indexable data file: docs/AnswerFields.jsonl.gz\n",
      "Checking data sub-directory: test2019\n",
      "Checking data sub-directory: test2020\n",
      "Checking data sub-directory: train_fusion\n",
      "Found query file: bitext/QuestionFields.jsonl\n",
      "Found query file: dev/QuestionFields.jsonl\n",
      "Found query file: dev_official/QuestionFields.jsonl\n",
      "Found query file: test2019/QuestionFields.jsonl\n",
      "Found query file: test2020/QuestionFields.jsonl\n",
      "Found query file: train_fusion/QuestionFields.jsonl\n",
      "JAVA_OPTS=-Xms12582912k -Xmx14680064k -server\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Processing field: 'text'\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index storage type: parsedText\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index storage type: mapdb\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Creating a new forward index, maximum # of docs to process: 2147483647\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D1484729'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D2338213'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D803785'\n",
      "...\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D2830667'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D2010'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D2545515'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D2145721'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D1840851'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D574433'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D664775'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D2322521'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D480933'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D740761'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D2625223'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D1601094'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D478881'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D2300752'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D2177053'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D2798037'\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 3200000 documents\n",
      "...\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D3027206'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D1250656'\n",
      "[main] WARN edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Warning: empty field 'text' for document 'D1636223'\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/msmarco_doc/input_data/docs/AnswerFields.jsonl.gz\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Final statistics: \n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Number of documents 3213802, total number of words 1532042624, average reduction due to keeping only unique words 2.002092\n",
      "JAVA_OPTS=-Xms12582912k -Xmx14680064k -server\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Processing field: 'text_raw'\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index storage type: raw\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index storage type: mapdb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Creating a new forward index, maximum # of docs to process: 2147483647\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 10000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 20000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 30000 documents\n",
      "...\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 880000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 890000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 900000 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 2720000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 2730000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 2740000 documents\n",
      "...\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 3190000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 3200000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 3210000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/msmarco_doc/input_data/docs/AnswerFields.jsonl.gz\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Final statistics: \n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Number of documents 3213802, total number of words 0, average reduction due to keeping only unique words 0.000000\n"
     ]
    }
   ],
   "source": [
    "!scripts/index/create_fwd_index.sh msmarco_doc mapdb \"text:parsedText text_raw:raw\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-23 14:13:36--  http://boytsov.info/models/msmarco_doc/2019/bert_vanilla/model.best\n",
      "Resolving boytsov.info (boytsov.info)... 69.60.127.165\n",
      "Connecting to boytsov.info (boytsov.info)|69.60.127.165|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 438863972 (419M) [text/plain]\n",
      "Saving to: ‘model.best’\n",
      "\n",
      "model.best          100%[===================>] 418.53M  1.42MB/s    in 4m 56s  \n",
      "\n",
      "2021-04-23 14:18:32 (1.42 MB/s) - ‘model.best’ saved [438863972/438863972]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget boytsov.info/models/msmarco_doc/2019/bert_vanilla/model.best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we do inference on CPU, which is pretty slow. To use a GPU change the ``DEVICE_NAME``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/FlexNeuART/scripts/py_flexneuart/venv/lib/python3.7/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Tanh' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VanillaBertRanker(\n",
       "  (bert): CustomBertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.05, inplace=False)\n",
       "  (cls): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#DEVICE_NAME='cuda:0'\n",
    "MAX_QUERY_LEN=32\n",
    "MAX_DOC_LEN=512 - 32 - 3\n",
    "BATCH_SIZE=16\n",
    "DEVICE_NAME='cpu'\n",
    "MODEL_FILE='model.best'\n",
    "model=torch.load(MODEL_FILE, map_location='cpu')\n",
    "model.to(DEVICE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference/API demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION='msmarco_doc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DOCNO': '961921',\n",
       " 'text': 'national park system establish',\n",
       " 'text_raw': 'when was the national park system established',\n",
       " 'text_bert_tok': 'when was the national park system established'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY_JSON={\"DOCNO\": \"961921\", \n",
    "            \"text\": \"national park system establish\",\n",
    "             \"text_raw\": \"when was the national park system established\", \"text_bert_tok\": \"when was the national park system established\"}\n",
    "QUERY_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.config import DOCID_FIELD, TEXT_FIELD_NAME, TEXT_RAW_FIELD_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.setup import *\n",
    "# add Java JAR to the class path\n",
    "configure_classpath('target')\n",
    "# create a resource manager\n",
    "resource_manager=create_featextr_resource_manager(f'collections/{COLLECTION}/forward_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.cand_provider import *\n",
    "# create a candidate provider/generator\n",
    "cand_prov = create_cand_provider(resource_manager, PROVIDER_TYPE_LUCENE, f'collections/{COLLECTION}/lucene_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('961921',\n",
       " (1152497,\n",
       "  [CandidateEntry(doc_id='D2527574', score=17.821687698364258),\n",
       "   CandidateEntry(doc_id='D1578783', score=17.796754837036133),\n",
       "   CandidateEntry(doc_id='D2398015', score=17.749736785888672),\n",
       "   CandidateEntry(doc_id='D2591882', score=17.310184478759766),\n",
       "   CandidateEntry(doc_id='D2443070', score=17.17824935913086),\n",
       "   CandidateEntry(doc_id='D2112934', score=17.16891860961914),\n",
       "   CandidateEntry(doc_id='D2106902', score=16.984983444213867),\n",
       "   CandidateEntry(doc_id='D1578782', score=16.844358444213867),\n",
       "   CandidateEntry(doc_id='D1019833', score=16.784225463867188),\n",
       "   CandidateEntry(doc_id='D3008908', score=16.633424758911133),\n",
       "   CandidateEntry(doc_id='D2769926', score=16.605653762817383),\n",
       "   CandidateEntry(doc_id='D797127', score=16.480308532714844),\n",
       "   CandidateEntry(doc_id='D2443068', score=16.377676010131836),\n",
       "   CandidateEntry(doc_id='D1578785', score=16.304927825927734),\n",
       "   CandidateEntry(doc_id='D1462277', score=16.298961639404297),\n",
       "   CandidateEntry(doc_id='D521200', score=16.226701736450195),\n",
       "   CandidateEntry(doc_id='D14553', score=16.180938720703125),\n",
       "   CandidateEntry(doc_id='D907579', score=16.174224853515625),\n",
       "   CandidateEntry(doc_id='D293688', score=16.149490356445312),\n",
       "   CandidateEntry(doc_id='D1151209', score=16.139711380004883)]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text=QUERY_JSON[TEXT_FIELD_NAME]\n",
    "query_id=QUERY_JSON[DOCID_FIELD]\n",
    "query_res=run_text_query(cand_prov, 20, query_text)\n",
    "query_id, query_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve a document (D1578782 is marked as a relevant entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.fwd_index import get_forward_index\n",
    "raw_indx = get_forward_index(resource_manager, 'text_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_ID='D1578782' # relevant\n",
    "#DOC_ID='D1462277' # not marked as relevant\n",
    "doc_text=raw_indx.get_doc_raw(DOC_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "national park system establish\n",
      "\n",
      "national park mashups \"national park service's 100 year birthday is in 2016. august 25, 2016 is the 100th birthday of the national park service. starting with yellowstone in 1872 there are over 400 units in the national park service today. how old is the system? the national park service was created by an act of congress and signed by president woodrow wilson on august 25, 1916. yellowstone national park was established by an act signed by president ulysses s. grant on march 1, 1872, as the nation's first national park. the mission of the national park service: the national park service preserves unimpaired the natural and cultural resources and values of the national park system for the enjoyment, education, and inspiration of this and future generations. the national park service cooperates with partners to extend the benefits of natural and cultural resource conservation and outdoor recreation throughout this country and the world. national park mashups news, videos, tweets, pictures, map blue ridge parkway cuyahoga valley national park grand canyon national park grand teton national park great smoky mountains national park olympic national park rocky mountain national park white sands national monument yellowstone national park yosemite national park zion national park how many areas are in the national park system? the national park system comprises 401 areas called \"\"units\"\" covering more than 84 million acres. these units include national parks, monuments, battlefields, military parks, historical parks, historic sites, lakeshores, recreation areas, scenic rivers and trails, and the white house. who are the people of the national park service? the national park service employs approximately 20,000 diverse professionals – permanent, temporary, and seasonal. they are assisted by nearly 140,000 volunteers-in-parks (vips) who donate over 5 million hours each year.©2006-present. all rights reserved. this site is not affiliated with the national park service, the us government or any us government agency. \"\n"
     ]
    }
   ],
   "source": [
    "print(query_text)\n",
    "print()\n",
    "print(doc_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score candidate documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_data = {}\n",
    "bm25_scores = {}\n",
    "for doc_id, bm25_score in query_res[1]:\n",
    "    doc_text = raw_indx.get_doc_raw(doc_id)\n",
    "    doc_data[doc_id] = doc_text\n",
    "    bm25_scores[doc_id] = bm25_score\n",
    "\n",
    "query_data = {query_id : query_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961921 D2527574 BM25 score: 17.821687698364258 model score: 1.320546269416809\n",
      "961921 D1578783 BM25 score: 17.796754837036133 model score: 0.8640079498291016\n",
      "961921 D2398015 BM25 score: 17.749736785888672 model score: 0.9334412813186646\n",
      "961921 D2591882 BM25 score: 17.310184478759766 model score: 1.2829281091690063\n",
      "961921 D2443070 BM25 score: 17.17824935913086 model score: 0.7396844625473022\n",
      "961921 D2112934 BM25 score: 17.16891860961914 model score: -1.9810694456100464\n",
      "961921 D2106902 BM25 score: 16.984983444213867 model score: -2.150390625\n",
      "961921 D1578782 BM25 score: 16.844358444213867 model score: 0.38077297806739807\n",
      "961921 D1019833 BM25 score: 16.784225463867188 model score: 0.6051344275474548\n",
      "961921 D3008908 BM25 score: 16.633424758911133 model score: -2.9435813426971436\n",
      "961921 D2769926 BM25 score: 16.605653762817383 model score: 0.5723978281021118\n",
      "961921 D797127 BM25 score: 16.480308532714844 model score: 0.06688592582941055\n",
      "961921 D2443068 BM25 score: 16.377676010131836 model score: 1.8065515756607056\n",
      "961921 D1578785 BM25 score: 16.304927825927734 model score: 2.141911506652832\n",
      "961921 D1462277 BM25 score: 16.298961639404297 model score: -1.862754225730896\n",
      "961921 D521200 BM25 score: 16.226701736450195 model score: -1.2749974727630615\n",
      "961921 D14553 BM25 score: 16.180938720703125 model score: 2.209441661834717\n",
      "961921 D907579 BM25 score: 16.174224853515625 model score: -0.7299518585205078\n",
      "961921 D293688 BM25 score: 16.149490356445312 model score: -1.9197825193405151\n",
      "961921 D1151209 BM25 score: 16.139711380004883 model score: -3.507384777069092\n"
     ]
    }
   ],
   "source": [
    "from scripts.cedr.data import iter_valid_records\n",
    "\n",
    "data_set = query_data, doc_data\n",
    "run = {query_id : doc_data.keys()}\n",
    "\n",
    "for records in iter_valid_records(model, DEVICE_NAME, data_set, run,\n",
    "                                       BATCH_SIZE,\n",
    "                                       MAX_QUERY_LEN, MAX_DOC_LEN):\n",
    "    scores = model(records['query_tok'],\n",
    "                    records['query_mask'],\n",
    "                    records['doc_tok'],\n",
    "                    records['doc_mask'])\n",
    "    \n",
    "    \n",
    "    scores = scores.tolist()\n",
    "\n",
    "    for qid, doc_id, score in zip(records['query_id'], records['doc_id'], scores):\n",
    "        print(f'{qid} {doc_id} BM25 score: {bm25_scores[doc_id]} model score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the document against the query (under the hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2120, 2380, 2291, 5323]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_bert_tok = model.tokenize(query_text)\n",
    "query_bert_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2120, 2136, 8499, 6210, 1010, 2120, 2136, 8499, 3574, 1064, 2394, 9206, 2120, 4215, 3501, 2487, 1997, 1010, 5994, 1010, 2030, 8800, 2000, 1037, 3842, 2004, 1037, 2878, 2475, 1997, 1010, 8800, 2000, 1010, 2030, 8281, 1997, 1037, 3327, 3842, 10760, 2120, 4377, 1997, 3735, 2509, 4678, 8986, 2594, 2030, 14314, 2078, 2549, 1037, 6926, 2030, 3395, 2629, 1037, 2120, 3780, 1626, 9582, 4748, 2615, 3060, 2120, 3519, 2078, 1006, 1999, 2148, 3088, 1007, 1037, 2576, 2283, 1010, 2631, 1999, 4878, 2004, 2019, 3060, 8986, 2929, 1998, 7917, 2045, 2013, 3624, 2000, 2901, 2138, 1997, 2049, 3161, 4559, 2000, 17862, 1024, 1999, 2807, 2180, 2148, 3088, 1005, 1055, 2034, 4800, 22648, 4818, 3864, 1010, 1006, 11113, 13578, 2615, 1012, 1007, 2019, 27421, 14778, 4509, 2120, 2283, 2078, 1006, 1999, 3725, 1007, 1037, 9253, 1011, 6394, 2576, 2283, 1010, 1006, 11113, 13578, 2615, 1007, 24869, 26952, 13033, 2120, 2078, 1996, 1012, 2019, 3296, 9561, 2571, 26300, 2448, 2012, 7110, 13334, 1010, 6220, 1010, 2144, 10011, 16523, 15094, 2120, 4031, 2078, 1996, 2561, 3643, 1997, 2035, 2345, 5350, 1998, 2578, 2550, 6604, 2011, 1037, 3842, 1010, 1006, 11113, 13578, 2615, 1012, 1007, 1043, 16275, 22254, 2937, 2120, 3519, 2078, 1996, 2880, 2171, 2005, 3519, 1006, 1996, 2576, 2283, 1007, 14791, 2120, 2380, 2078, 1037, 2120, 2380, 1999, 25430, 2710, 1010, 1999, 1059, 7649, 1999, 1996, 22366, 1024, 6870, 8493, 1012, 2181, 1024, 11518, 8889, 5490, 1012, 2463, 1006, 17442, 2692, 5490, 1012, 2661, 1007, 27823, 2120, 2380, 2078, 1037, 6870, 8493, 1999, 11265, 2148, 3088, 1024, 1996, 2088, 1005, 1055, 2922, 2208, 3914, 1012, 2181, 1024, 2058, 20335, 8889, 5490, 1012, 2463, 1006, 28122, 2692, 5490, 1012, 2661, 1007, 23714, 5430, 2120, 2380, 2078, 1037, 2120, 2380, 1999, 1059, 2430, 5612, 1024, 2511, 1999, 3874, 2000, 4047, 1037, 2291, 1997, 9771, 16679, 2015, 4057, 11338, 12631, 3051, 2120, 2380, 2078, 1037, 2120, 2380, 1999, 1055, 2430, 7397, 1024, 3397, 2112, 1997, 1996, 7397, 2846, 2181, 1024, 6275, 22610, 5490, 1012, 2463, 1006, 19988, 2692, 5490, 1012, 2661, 1007, 4057, 4542, 3771, 2120, 2380, 2078, 1037, 2120, 2380, 1999, 1059, 2899, 1010, 1999, 1996, 16690, 2846, 1012, 2181, 1024, 5989, 2575, 5490, 1012, 2463, 1006, 4261, 2581, 5490, 1012, 2661, 1007, 2120, 2078, 1996, 1012, 2460, 2005, 1996, 1585, 2882, 2120, 25434, 9529, 2078, 2178, 2171, 2005, 1585, 2591, 9529, 25434, 3820, 2078, 2517, 5337, 10540, 5266, 6165, 1997, 3477, 1998, 2060, 3408, 1998, 3785, 1997, 6107, 2008, 2024, 1996, 2765, 1997, 7268, 21990, 2012, 2120, 2504, 2090, 2028, 2030, 2062, 3119, 9209, 1998, 12433, 1999, 1037, 4753, 1997, 1996, 4610, 25434, 11971, 2078, 1037, 14314, 14825, 2030, 2060, 2299, 4233, 2011, 1037, 3842, 2005, 2224, 2006, 2270, 2030, 2110, 6642, 2120, 3320, 2078, 1006, 2413, 2381, 1007, 1996, 2303, 11846, 2011, 1996, 2413, 2353, 3776, 1999, 2238, 13739, 2044, 1996, 4214, 1997, 1996, 8707, 2236, 1012, 2009, 2001, 8314, 1999, 17419, 1012, 14362, 2000, 2022, 2999, 2011, 1996, 2047, 4884, 3320, 25434, 5375, 2078, 1006, 1999, 3725, 1007, 3839, 1037, 4882, 21447, 3825, 2000, 3056, 2111, 2011, 1996, 2110, 2000, 3288, 2037, 29373, 2039, 2000, 6263, 3798, 2511, 2011, 2375, 2085, 2999, 2011, 1585, 3318, 2490, 25434, 2924, 2078, 2487, 1006, 1999, 1996, 1057, 1012, 1055, 1012, 1007, 1037, 3293, 2924, 5100, 2104, 1037, 2976, 6111, 1998, 10142, 3223, 2000, 2022, 1037, 2266, 1997, 1996, 2976, 3914, 2291, 12826, 1585, 2110, 2924, 2475, 1037, 2924, 3079, 1998, 3498, 2011, 1037, 2231, 2120, 4879, 1997, 4781, 2078, 1006, 1057, 1012, 1055, 1007, 2019, 3029, 1010, 2631, 1999, 5775, 1010, 3005, 3853, 2003, 2000, 5323, 1998, 5441, 4781, 2005, 3197, 1997, 11702, 12826, 1585, 2329, 4781, 5145, 1585, 2248, 4781, 3029, 25434, 3642, 2078, 2178, 2744, 2005, 1585, 2827, 3513, 2120, 4680, 2078, 2487, 1037, 4680, 2218, 2296, 2176, 2086, 2011, 2169, 2350, 1057, 1012, 1055, 1012, 2576, 2283, 2000, 5454, 2049, 4883, 4018, 2475, 1006, 2413, 2381, 1007, 1996, 6493, 9879, 1997, 1996, 6208, 17720, 1010, 9879, 2013, 17419, 1012, 13414, 2000, 13323, 1012, 13397, 1010, 2043, 2009, 2001, 2999, 2011, 1996, 14176, 2120, 2406, 2283, 2078, 1006, 1999, 2660, 1007, 1037, 2280, 2171, 2005, 1585, 2120, 2283, 1006, 11113, 13578, 2615, 1012, 1007, 13316, 2361, 25434, 16077, 2078, 2156, 1585, 16077, 2120, 8882, 2078, 1006, 1999, 2563, 1998, 3575, 1007, 1996, 8882, 1997, 5739, 4036, 1999, 2110, 2816, 20519, 2013, 2960, 1012, 2045, 2024, 2702, 3192, 5739, 1024, 2394, 1010, 8785, 2015, 1010, 1998, 2671, 1006, 1996, 4563, 5739, 1007, 1025, 2396, 1010, 2640, 1998, 2974, 1010, 10505, 1010, 2381, 1010, 2189, 1010, 3558, 2495, 1010, 1998, 1037, 3097, 2653, 1012, 7391, 2024, 14155, 2429, 2000, 9675, 18759, 3672, 7889, 2802, 2169, 1997, 2176, 3145, 5711, 1012, 2816, 2442, 2036, 3073, 3412, 2495, 1998, 2013, 2639, 8220, 1999, 9068, 25434, 7016, 2078, 1996, 2561, 5151, 23733, 2015, 1997, 1037, 3842, 1005, 1055, 2430, 2231, 1010, 1006, 2036, 2170, 1006, 9686, 2361, 1012, 1057, 1012, 1055, 1012, 1007, 1007, 2270, 7016, 2120, 3171, 2458, 2473, 2078, 2019, 7319, 2303, 2006, 2236, 3171, 3343, 1999, 3725, 1010, 3605, 1997, 4505, 1997, 2231, 1010, 2968, 1010, 1998, 3119, 9209, 1024, 2511, 1999, 3705, 1025, 8961, 1999, 2826, 1010, 1006, 11113, 13578, 15088, 1012, 1007, 12311, 2278, 1006, 11900, 1007, 12311, 5149, 2120, 6960, 2604, 2078, 1037, 2270, 3840, 2511, 1999, 3339, 2000, 2393, 1996, 4610, 1997, 1996, 2866, 1012, 1999, 3261, 2009, 5314, 2007, 1996, 2120, 2470, 1998, 2458, 2473, 2000, 2433, 1996, 2329, 2974, 2177, 1010, 1006, 11113, 13578, 2615, 1012, 1007, 11265, 24700, 3370, 2389, 2392, 2078, 1006, 1999, 3725, 1007, 1037, 2235, 2576, 2283, 1997, 1996, 2157, 2007, 16939, 1998, 2060, 4654, 7913, 23738, 6043, 1010, 1006, 11113, 13578, 2615, 1012, 1007, 1050, 2546, 25434, 3916, 2078, 1037, 2350, 2396, 3916, 1999, 2414, 1010, 1999, 19817, 10354, 2389, 6843, 2675, 1012, 2631, 1999, 11617, 1010, 2009, 3397, 1996, 2922, 3074, 1997, 5265, 1999, 3725, 25434, 8370, 2078, 2487, 1006, 28101, 1007, 1037, 2897, 1997, 2152, 1011, 10004, 2373, 3210, 7176, 2350, 2373, 3703, 2475, 1037, 8370, 1997, 12046, 12093, 2109, 2011, 1996, 14445, 5002, 1999, 3725, 1998, 3163, 1998, 1999, 2047, 3414, 2011, 1996, 2047, 3414, 4915, 1998, 5002, 2533, 1998, 6267, 2006, 2037, 7341, 2120, 3457, 2078, 2487, 2823, 2025, 9700, 1996, 4273, 2486, 1010, 2034, 6311, 2011, 14425, 1010, 2008, 2001, 2511, 1999, 2605, 1999, 13739, 1998, 5839, 23852, 2135, 2127, 7428, 2475, 1006, 1999, 1996, 1057, 1012, 1055, 1012, 1007, 1037, 2110, 2510, 2486, 2008, 2064, 2022, 2170, 2046, 2976, 2326, 2011, 1996, 2343, 2120, 2740, 2326, 2078, 1006, 1999, 3725, 1007, 1996, 2291, 1997, 2120, 2966, 2578, 2144, 3882, 1010, 13790, 3701, 2011, 14952, 25434, 5690, 2078, 1006, 28101, 1007, 2411, 6178, 2050, 1996, 3868, 1997, 5194, 2006, 15948, 2015, 2007, 14523, 2497, 1006, 2004, 16913, 18095, 1007, 1037, 2120, 5690, 13989, 25434, 3318, 2078, 1006, 5543, 1007, 1996, 2561, 1997, 2035, 29373, 16222, 6820, 2075, 2058, 1037, 9675, 2558, 2000, 3901, 1997, 1037, 2406, 1998, 5398, 1997, 12678, 1010, 20566, 1010, 11372, 1010, 9278, 1010, 1998, 3037, 25434, 5427, 2078, 1006, 1999, 3725, 1007, 2110, 5427, 2241, 2006, 4882, 5857, 2013, 5126, 1998, 12433, 1998, 4346, 10504, 2000, 1996, 18787, 1010, 1996, 5305, 1010, 1996, 3394, 1010, 4385, 1012, 1010, 2004, 2092, 2004, 2966, 2578, 2156, 2036, 1585, 2591, 3036, 2120, 7931, 2392, 2078, 2487, 2823, 2025, 9700, 1037, 6208, 2929, 2008, 11014, 1996, 2120, 4336, 1997, 1037, 2406, 1010, 2788, 2011, 15722, 8309, 2475, 1006, 2036, 2170, 1007, 2120, 7931, 2392, 1997, 2148, 5148, 1037, 2576, 3029, 2719, 1999, 2148, 5148, 1999, 3624, 2011, 1996, 19710, 8663, 16989, 3508, 2389, 2380, 2078, 2019, 2181, 1997, 10833, 2005, 2270, 2224, 4351, 2011, 1037, 2120, 2231, 2004, 2108, 1997, 3862, 12916, 1010, 4483, 1010, 2030, 3439, 5197, 2120, 2380, 2078, 1037, 14897, 10942, 2555, 1999, 2047, 3414, 1010, 1999, 1996, 2430, 2167, 2479, 1024, 8301, 7001, 2120, 2283, 2078, 2487, 1006, 1999, 2047, 3414, 1007, 1996, 2062, 4603, 1997, 1996, 2048, 2364, 2576, 4243, 2475, 1006, 1999, 2660, 1007, 1037, 2576, 2283, 5059, 2049, 2364, 2490, 2013, 3541, 2752, 1010, 1006, 2280, 2171, 1007, 2120, 2406, 2283, 2509, 1006, 1999, 2148, 3088, 1007, 1037, 2576, 2283, 3605, 3701, 1997, 2803, 1011, 2000, 1011, 2157, 1011, 3358, 21358, 23778, 16912, 1012, 2009, 5451, 2013, 3882, 2127, 1996, 2406, 1005, 1055, 2034, 4800, 22648, 4818, 3864, 1999, 2807, 2043, 2009, 2001, 3249, 2011, 1996, 3060, 2120, 3519, 2156, 2036, 1585, 6555, 2976, 2283, 1585, 2142, 2283, 2120, 3558, 5911, 2078, 1037, 2866, 5069, 2631, 1999, 5141, 2012, 6945, 21504, 2000, 4287, 2041, 2470, 1999, 5584, 1998, 8080, 4781, 1997, 10903, 1010, 1006, 11113, 13578, 2615, 1012, 1007, 27937, 19666, 3370, 2389, 6533, 3916, 2078, 2019, 2396, 3916, 1999, 2414, 1010, 2511, 1999, 8708, 1010, 14962, 9668, 1998, 7008, 1997, 14953, 4481, 1999, 2329, 2381, 2120, 10995, 2924, 2078, 1006, 1999, 3725, 1007, 1037, 2231, 10995, 2924, 1010, 2448, 2083, 1996, 2695, 2436, 1010, 9686, 2361, 1012, 2005, 2235, 3828, 2869, 2120, 2082, 2078, 2487, 1006, 1999, 3163, 1007, 1037, 2110, 3078, 2082, 2475, 1006, 1999, 2563, 1999, 1996, 3708, 2301, 1007, 1037, 2082, 2448, 2011, 1996, 2277, 1997, 2563, 2005, 1996, 2336, 1997, 1996, 3532, 25434, 2326, 2078, 1006, 15897, 28101, 1007, 14770, 2510, 2326, 2120, 14649, 2078, 1006, 2446, 2381, 1007, 1996, 23252, 1998, 6078, 1997, 1996, 13157, 1010, 5994, 1996, 22006, 1997, 8042, 2004, 11865, 17875, 1010, 3424, 1011, 4100, 17456, 1010, 2110, 2491, 1997, 1996, 4610, 1010, 1998, 2120, 4935, 1010, 1006, 2036, 2170, 1007, 13157, 2213, 1010, 6394, 2964, 1626, 2120, 6102, 1050, 1010, 4748, 22895, 3370, 2389, 3565, 11639, 14505, 2078, 1006, 1050, 1012, 1062, 1007, 1037, 2965, 1011, 3141, 11550, 3825, 2000, 9750, 2111, 2120, 3004, 2078, 1996, 2280, 2171, 1997, 1996, 1585, 2548, 2120, 3004, 2120, 3404, 2078, 2487, 1006, 1999, 3725, 1007, 2019, 3029, 4986, 2007, 1996, 8347, 1997, 3181, 3121, 1998, 10490, 1998, 2752, 1997, 1996, 10833, 1997, 2307, 5053, 1999, 2563, 1010, 3575, 1010, 1998, 2642, 3163, 1012, 2009, 2001, 2631, 1999, 6301, 1998, 5100, 2011, 2552, 1997, 3323, 1999, 5528, 1012, 1996, 2120, 3404, 2005, 3885, 2001, 2631, 1999, 4739, 2475, 1006, 1999, 2660, 1007, 1037, 2714, 3029, 1999, 2169, 1997, 1996, 2163, 7159, 2120, 4031, 2078, 7977, 2120, 4031, 15718, 2019, 21447, 2005, 1996, 2139, 28139, 23247, 1997, 3007, 5350, 1010, 1006, 11113, 13578, 2615, 1012, 1007, 1050, 16275, 12952, 4355, 15830, 2120, 3691, 2078, 1996, 3691, 2719, 1999, 2807, 2000, 21208, 1996, 9302, 8564, 6500, 1024, 2009, 7711, 3343, 2006, 2740, 1010, 2495, 1010, 2591, 7574, 1010, 3622, 14952, 1010, 6813, 1010, 1998, 3226, 1998, 9020, 3864, 2000, 1996, 9302, 2473, 1010, 1006, 11113, 13578, 2615, 1012, 1007, 1052, 11802, 18232, 2140, 2120, 3004, 2078, 1037, 3004, 3375, 1999, 2414, 1010, 2006, 1996, 1055, 2924, 1997, 1996, 11076, 1006, 2441, 3299, 1007, 1012, 1996, 17576, 2548, 2001, 2794, 1999, 2997, 1012, 2009, 3506, 1996, 2548, 2120, 3004, 2194, 4104, 2120, 2283, 2078, 1037, 2576, 2283, 20324, 1996, 4336, 1997, 3885, 1010, 2631, 1999, 4579, 1010, 1006, 11113, 13578, 2615, 1012, 1007, 1055, 16275, 1626, 4104, 8986, 1006, 11900, 1007, 1626, 8040, 4140, 14085, 1050, 1010, 4748, 3501, 7367, 28940, 25463, 2120, 2380, 2078, 1037, 2120, 2380, 1999, 2430, 2662, 1010, 1999, 1996, 7838, 7756, 4020, 1024, 2511, 1999, 6193, 2000, 4047, 21695, 1997, 5016, 7367, 28940, 25463, 2015, 1010, 2070, 1997, 2029, 2024, 2055, 20143, 2086, 2214, 1012, 2181, 1024, 14168, 2575, 5490, 1012, 2463, 1006, 3438, 2487, 5490, 1012, 2661, 1007, 21882, 28574, 4430, 2120, 2380, 2078, 1037, 2120, 2380, 1999, 1050, 3448, 1024, 2511, 1999, 4437, 2000, 4047, 2112, 1997, 1996, 2630, 5526, 4020, 1012, 2181, 1024, 6275, 2475, 5490, 1012, 2463, 1006, 22060, 5490, 1012, 2661, 1007, 29231, 2120, 2380, 2078, 1037, 2120, 2380, 1999, 1996, 22064, 2430, 1057, 1012, 1055, 1012, 1010, 3262, 1999, 22064, 10622, 1024, 1996, 4587, 1998, 2922, 2120, 2380, 1999, 1996, 1057, 1012, 1055, 1012, 1010, 4820, 5866, 9843, 13197, 1998, 16216, 23274, 2869, 1012, 2181, 1024, 6486, 26976, 5490, 1012, 2463, 1006, 23785, 2620, 5490, 1012, 2661, 1007, 10930, 3366, 23419, 2120, 2380, 2078, 1037, 2120, 2380, 1999, 2430, 2662, 1010, 1999, 1996, 7838, 7756, 4020, 1024, 3397, 1996, 10930, 3366, 23419, 3028, 1010, 2012, 2019, 7998, 1997, 2055, 14840, 1049, 1006, 20143, 3027, 1012, 1007, 1010, 2007, 11591, 3681, 4803, 2055, 2178, 14840, 1049, 1006, 20143, 3027, 1012, 1007, 1012, 2181, 1024, 24622, 2487, 5490, 1012, 2463, 1006, 12963, 2475, 5490, 1012, 2661, 1007, 2394, 6868, 9206, 1011, 2394, 6210, 1004, 1996, 22244] 2066\n"
     ]
    }
   ],
   "source": [
    "doc_bert_tok = model.tokenize(doc_text)\n",
    "print(doc_bert_tok, len(doc_bert_tok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is important to truncate queries and documents ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_bert_tok=query_bert_tok[0:MAX_QUERY_LEN]\n",
    "doc_bert_tok=doc_bert_tok[0:MAX_DOC_LEN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... and pad queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2120, 2380, 2291, 5323, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "from scripts.cedr.data import PAD_CODE\n",
    "\n",
    "query_bert_tok_pad = query_bert_tok + [PAD_CODE] * (MAX_QUERY_LEN - len(query_bert_tok))\n",
    "print(query_bert_tok_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call unsqueeze(0) is required to create a batch dimension (we can have multiple queries & documents batched together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 477)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tok_tensor_pad = torch.LongTensor(query_bert_tok_pad).unsqueeze(0).to(DEVICE_NAME)\n",
    "doc_tok_tensor = torch.LongTensor(doc_bert_tok).unsqueeze(0).to(DEVICE_NAME)\n",
    "len(query_tok_tensor_pad[0]), len(doc_tok_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32]), torch.Size([1, 477]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tok_tensor_pad.shape, doc_tok_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_mask = torch.FloatTensor([1.0] * len(query_bert_tok) + \n",
    "                              [0.] * (MAX_QUERY_LEN - len(query_bert_tok))).unsqueeze(0).to(DEVICE_NAME)\n",
    "doc_mask = torch.ones_like(doc_tok_tensor).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32]), torch.Size([1, 477]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_mask.shape, doc_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_mask, doc_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.5074], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(query_tok_tensor_pad, query_mask, doc_tok_tensor, doc_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}