{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the repo is cloned, all necessary packages are installed, including calling the script:\n",
    "\n",
    "```./install_packages.sh```\n",
    "\n",
    "and the code is compiled:\n",
    "\n",
    "```./build.sh```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing directory to the repo root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading demo data\n",
    "\n",
    "1. Download [this file from our Google Drive](https://drive.google.com/file/d/1mDa6J4hNYPyqlS8hVi6bykSbAOMKsDwe/view?usp=sharing) and copy it to the source root directory, where it should be unpacked. As a result, a source directory should contain a sub-directory ``collections/msmarco_doc``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: statistics on downloaded data should look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "Checking data sub-directory: bitext\n",
      "Checking data sub-directory: bitext_msmarco_pass_mixed_qrels\n",
      "Checking data sub-directory: bitext_msmarco_pass_part0\n",
      "Checking data sub-directory: bitext_msmarco_pass_part1\n",
      "Checking data sub-directory: bitext_msmarco_pass_part2\n",
      "Checking data sub-directory: bitext_msmarco_pass_pseudo_qrels\n",
      "Checking data sub-directory: bitext_orcas_minqty_5\n",
      "Checking data sub-directory: dev\n",
      "Checking data sub-directory: dev1\n",
      "Checking data sub-directory: dev2\n",
      "Checking data sub-directory: dev2.single_doc_query\n",
      "Checking data sub-directory: docs\n",
      "Found indexable data file: docs/AnswerFields.jsonl.gz\n",
      "Checking data sub-directory: lb2020\n",
      "Checking data sub-directory: test2019\n",
      "Checking data sub-directory: test2020\n",
      "Checking data sub-directory: train1\n",
      "Checking data sub-directory: train.dont_use\n",
      "Found query file: bitext/QuestionFields.jsonl\n",
      "Found query file: bitext_msmarco_pass_mixed_qrels/QuestionFields.jsonl\n",
      "Found query file: bitext_msmarco_pass_part0/QuestionFields.jsonl\n",
      "Found query file: bitext_msmarco_pass_part1/QuestionFields.jsonl\n",
      "Found query file: bitext_msmarco_pass_part2/QuestionFields.jsonl\n",
      "Found query file: bitext_msmarco_pass_pseudo_qrels/QuestionFields.jsonl\n",
      "Found query file: bitext_orcas_minqty_5/QuestionFields.jsonl\n",
      "Found query file: dev/QuestionFields.jsonl\n",
      "Found query file: dev1/QuestionFields.jsonl\n",
      "Found query file: dev2/QuestionFields.jsonl\n",
      "Found query file: dev2.single_doc_query/QuestionFields.jsonl\n",
      "Found query file: lb2020/QuestionFields.jsonl\n",
      "Found query file: test2019/QuestionFields.jsonl\n",
      "Found query file: test2020/QuestionFields.jsonl\n",
      "Found query file: train1/QuestionFields.jsonl\n",
      "Found query file: train.dont_use/QuestionFields.jsonl\n",
      "getIndexQueryDataInfo return value:  docs AnswerFields.jsonl.gz ,bitext,bitext_msmarco_pass_mixed_qrels,bitext_msmarco_pass_part0,bitext_msmarco_pass_part1,bitext_msmarco_pass_part2,bitext_msmarco_pass_pseudo_qrels,bitext_orcas_minqty_5,dev,dev1,dev2,dev2.single_doc_query,lb2020,test2019,test2020,train1,train.dont_use QuestionFields.jsonl\n",
      "Using the data input files: AnswerFields.jsonl.gz, QuestionFields.jsonl\n",
      "Index dirs: docs\n",
      "Query dirs:  bitext bitext_msmarco_pass_mixed_qrels bitext_msmarco_pass_part0 bitext_msmarco_pass_part1 bitext_msmarco_pass_part2 bitext_msmarco_pass_pseudo_qrels bitext_orcas_minqty_5 dev dev1 dev2 dev2.single_doc_query lb2020 test2019 test2020 train1 train.dont_use\n",
      "Queries/questions:\n",
      "bitext 357013\n",
      "bitext_msmarco_pass_mixed_qrels 787462\n",
      "bitext_msmarco_pass_part0 262911\n",
      "bitext_msmarco_pass_part1 262911\n",
      "bitext_msmarco_pass_part2 262909\n",
      "bitext_msmarco_pass_pseudo_qrels 787462\n",
      "bitext_orcas_minqty_5 910899\n",
      "dev 5193\n",
      "dev1 2500\n",
      "dev2 2693\n",
      "dev2.single_doc_query 1\n",
      "lb2020 5793\n",
      "test2019 43\n",
      "test2020 45\n",
      "train1 10000\n",
      "train.dont_use 367013\n",
      "Documents/passages/answers:\n",
      "docs 44860979\n"
     ]
    }
   ],
   "source": [
    "!scripts/report/get_basic_collect_stat.sh msmarco_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing (each step takes a few hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lucene index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/index/create_lucene_index.sh msmarco_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward indices (text is not really necessary for this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scripts/index/create_fwd_index.sh msmarco_doc mapdb \"text:parsedText text_raw:raw\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-07 13:44:14--  http://boytsov.info/models/msmarco_doc/2019/bert_vanilla/model.best\n",
      "Resolving boytsov.info (boytsov.info)... 69.60.127.165\n",
      "Connecting to boytsov.info (boytsov.info)|69.60.127.165|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 438863972 (419M) [text/plain]\n",
      "Saving to: ‘model.best’\n",
      "\n",
      "model.best          100%[===================>] 418.53M  3.08MB/s    in 2m 26s  \n",
      "\n",
      "2021-02-07 13:46:41 (2.86 MB/s) - ‘model.best’ saved [438863972/438863972]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget boytsov.info/models/msmarco_doc/2019/bert_vanilla/model.best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we do inference on CPU, which is pretty slow. To use a GPU change the ``DEVICE_NAME``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VanillaBertRanker(\n",
       "  (bert): CustomBertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.05, inplace=False)\n",
       "  (cls): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#DEVICE_NAME='cuda:0'\n",
    "MAX_QUERY_LEN=32\n",
    "MAX_DOC_LEN=512 - 32 - 3\n",
    "BATCH_SIZE=16\n",
    "DEVICE_NAME='cpu'\n",
    "MODEL_FILE='model.best'\n",
    "model=torch.load(MODEL_FILE, map_location='cpu')\n",
    "model.to(DEVICE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference/API demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION='msmarco_doc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DOCNO': '961921',\n",
       " 'text': 'national park system establish',\n",
       " 'text_raw': 'when was the national park system established',\n",
       " 'text_bert_tok': 'when was the national park system established'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY_JSON={\"DOCNO\": \"961921\", \n",
    "            \"text\": \"national park system establish\",\n",
    "             \"text_raw\": \"when was the national park system established\", \"text_bert_tok\": \"when was the national park system established\"}\n",
    "QUERY_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.config import DOCID_FIELD, TEXT_FIELD_NAME, TEXT_RAW_FIELD_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.setup import *\n",
    "# add Java JAR to the class path\n",
    "configure_classpath('target')\n",
    "# create a resource manager\n",
    "resource_manager=create_featextr_resource_manager(f'collections/{COLLECTION}/forward_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.cand_provider import *\n",
    "# create a candidate provider/generator\n",
    "cand_prov = create_cand_provider(resource_manager, PROVIDER_TYPE_LUCENE, f'collections/{COLLECTION}/lucene_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('961921',\n",
       " (1204206,\n",
       "  [CandidateEntry(doc_id='D2527574', score=18.659997940063477),\n",
       "   CandidateEntry(doc_id='D2398015', score=18.492298126220703),\n",
       "   CandidateEntry(doc_id='D1578785', score=18.234092712402344),\n",
       "   CandidateEntry(doc_id='D2189735', score=18.2298583984375),\n",
       "   CandidateEntry(doc_id='D1578782', score=17.947647094726562),\n",
       "   CandidateEntry(doc_id='D2527573', score=17.892498016357422),\n",
       "   CandidateEntry(doc_id='D1578784', score=17.88416862487793),\n",
       "   CandidateEntry(doc_id='D2106902', score=17.869140625),\n",
       "   CandidateEntry(doc_id='D2591882', score=17.70314598083496),\n",
       "   CandidateEntry(doc_id='D2443070', score=17.63814926147461),\n",
       "   CandidateEntry(doc_id='D1578783', score=17.51651382446289),\n",
       "   CandidateEntry(doc_id='D3525662', score=17.447235107421875),\n",
       "   CandidateEntry(doc_id='D2769926', score=17.322866439819336),\n",
       "   CandidateEntry(doc_id='D1737386', score=17.243505477905273),\n",
       "   CandidateEntry(doc_id='D1514002', score=17.16539192199707),\n",
       "   CandidateEntry(doc_id='D14552', score=17.148212432861328),\n",
       "   CandidateEntry(doc_id='D2443068', score=17.124448776245117),\n",
       "   CandidateEntry(doc_id='D2893132', score=17.09151268005371),\n",
       "   CandidateEntry(doc_id='D1581803', score=17.08568572998047),\n",
       "   CandidateEntry(doc_id='D1462277', score=17.0462589263916)]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text=QUERY_JSON[TEXT_FIELD_NAME]\n",
    "query_id=QUERY_JSON[DOCID_FIELD]\n",
    "query_res=run_text_query(cand_prov, 20, query_text)\n",
    "query_id, query_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve a document (D1578782 is marked as a relevant entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.fwd_index import get_forward_index\n",
    "raw_indx = get_forward_index(resource_manager, 'text_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_ID='D1578782' # relevant\n",
    "#DOC_ID='D1462277' # not marked as relevant\n",
    "doc_text=raw_indx.get_doc_raw(DOC_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "national park system establish\n",
      "\n",
      "national park mashups \"national park service's 100 year birthday is in 2016. august 25, 2016 is the 100th birthday of the national park service. starting with yellowstone in 1872 there are over 400 units in the national park service today. how old is the system? the national park service was created by an act of congress and signed by president woodrow wilson on august 25, 1916. yellowstone national park was established by an act signed by president ulysses s. grant on march 1, 1872, as the nation's first national park. the mission of the national park service: the national park service preserves unimpaired the natural and cultural resources and values of the national park system for the enjoyment, education, and inspiration of this and future generations. the national park service cooperates with partners to extend the benefits of natural and cultural resource conservation and outdoor recreation throughout this country and the world. national park mashups news, videos, tweets, pictures, map blue ridge parkway cuyahoga valley national park grand canyon national park grand teton national park great smoky mountains national park olympic national park rocky mountain national park white sands national monument yellowstone national park yosemite national park zion national park how many areas are in the national park system? the national park system comprises 401 areas called \"\"units\"\" covering more than 84 million acres. these units include national parks, monuments, battlefields, military parks, historical parks, historic sites, lakeshores, recreation areas, scenic rivers and trails, and the white house. who are the people of the national park service? the national park service employs approximately 20,000 diverse professionals – permanent, temporary, and seasonal. they are assisted by nearly 140,000 volunteers-in-parks (vips) who donate over 5 million hours each year.©2006-present. all rights reserved. this site is not affiliated with the national park service, the us government or any us government agency. \"\n"
     ]
    }
   ],
   "source": [
    "print(query_text)\n",
    "print()\n",
    "print(doc_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score candidate documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_data = {}\n",
    "bm25_scores = {}\n",
    "for doc_id, bm25_score in query_res[1]:\n",
    "    doc_text = raw_indx.get_doc_raw(doc_id)\n",
    "    doc_data[doc_id] = doc_text\n",
    "    bm25_scores[doc_id] = bm25_score\n",
    "\n",
    "query_data = {query_id : query_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961921 D2527574 BM25 score: 18.659997940063477 model score: 1.320546269416809\n",
      "961921 D2398015 BM25 score: 18.492298126220703 model score: 0.9334409236907959\n",
      "961921 D1578785 BM25 score: 18.234092712402344 model score: 2.141911029815674\n",
      "961921 D2189735 BM25 score: 18.2298583984375 model score: -0.07196071743965149\n",
      "961921 D1578782 BM25 score: 17.947647094726562 model score: 0.38077396154403687\n",
      "961921 D2527573 BM25 score: 17.892498016357422 model score: 0.9013162851333618\n",
      "961921 D1578784 BM25 score: 17.88416862487793 model score: 1.047125220298767\n",
      "961921 D2106902 BM25 score: 17.869140625 model score: -2.150390386581421\n",
      "961921 D2591882 BM25 score: 17.70314598083496 model score: 1.2829278707504272\n",
      "961921 D2443070 BM25 score: 17.63814926147461 model score: 0.7396841645240784\n",
      "961921 D1578783 BM25 score: 17.51651382446289 model score: 0.8640072345733643\n",
      "961921 D3525662 BM25 score: 17.447235107421875 model score: 1.0577561855316162\n",
      "961921 D2769926 BM25 score: 17.322866439819336 model score: 0.5723984837532043\n",
      "961921 D1737386 BM25 score: 17.243505477905273 model score: 0.17278951406478882\n",
      "961921 D1514002 BM25 score: 17.16539192199707 model score: -2.0407660007476807\n",
      "961921 D14552 BM25 score: 17.148212432861328 model score: -2.3776450157165527\n",
      "961921 D2443068 BM25 score: 17.124448776245117 model score: 1.8065520524978638\n",
      "961921 D2893132 BM25 score: 17.09151268005371 model score: -2.4445197582244873\n",
      "961921 D1581803 BM25 score: 17.08568572998047 model score: -0.9361811876296997\n",
      "961921 D1462277 BM25 score: 17.0462589263916 model score: -1.8627537488937378\n"
     ]
    }
   ],
   "source": [
    "from scripts.cedr.data import iter_valid_records\n",
    "\n",
    "data_set = query_data, doc_data\n",
    "run = {query_id : doc_data.keys()}\n",
    "\n",
    "for records in iter_valid_records(model, DEVICE_NAME, data_set, run,\n",
    "                                       BATCH_SIZE,\n",
    "                                       MAX_QUERY_LEN, MAX_DOC_LEN):\n",
    "    scores = model(records['query_tok'],\n",
    "                    records['query_mask'],\n",
    "                    records['doc_tok'],\n",
    "                    records['doc_mask'])\n",
    "    \n",
    "    \n",
    "    scores = scores.tolist()\n",
    "\n",
    "    for qid, doc_id, score in zip(records['query_id'], records['doc_id'], scores):\n",
    "        print(f'{qid} {doc_id} BM25 score: {bm25_scores[doc_id]} model score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the document against the query (under the hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2120, 2380, 2291, 5323]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_bert_tok = model.tokenize(query_text)\n",
    "query_bert_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10117, 8573, 1998, 5680, 1000, 1000, 1000, 2057, 2031, 5357, 15891, 2000, 1996, 2087, 14013, 4348, 1037, 2111, 2412, 2363, 1010, 1998, 2169, 2028, 2442, 2079, 2010, 2112, 2065, 2057, 4299, 2000, 2265, 2008, 1996, 3842, 2003, 11007, 1997, 2049, 2204, 7280, 1012, 1000, 1000, 1011, 10117, 8573, 8573, 2018, 2023, 3746, 2579, 2005, 1996, 3104, 1997, 2010, 2338, 1010, 1000, 1000, 5933, 9109, 1997, 1037, 8086, 2386, 1012, 1000, 1000, 17590, 2110, 2118, 10117, 8573, 2003, 2411, 2641, 1996, 1000, 1000, 5680, 2923, 2343, 1012, 1000, 1000, 2182, 1999, 1996, 2167, 7734, 2919, 8653, 1010, 2073, 2116, 1997, 2010, 3167, 5936, 2034, 2435, 4125, 2000, 2010, 2101, 4483, 4073, 1010, 8573, 2003, 4622, 2007, 1037, 2120, 2380, 2008, 6468, 2010, 2171, 1998, 7836, 1996, 3638, 1997, 2023, 2307, 5680, 2923, 1012, 10117, 8573, 2034, 2234, 2000, 1996, 2919, 8653, 1999, 2244, 7257, 1012, 1037, 27168, 1011, 4477, 2035, 2010, 2166, 1010, 8573, 4912, 1037, 3382, 2000, 5690, 1996, 2502, 2208, 1997, 2167, 2637, 2077, 2027, 5419, 1012, 2348, 2010, 7896, 17120, 3365, 5933, 9109, 1998, 3144, 8563, 1010, 2027, 2024, 17958, 2007, 20342, 3372, 2005, 1996, 3279, 1997, 2427, 1998, 6552, 1012, 1996, 11703, 9581, 3508, 1997, 22285, 1010, 1998, 1996, 3690, 25027, 1997, 18995, 1010, 2502, 9769, 8351, 1010, 8448, 1998, 2060, 2208, 2427, 2001, 1037, 3279, 2029, 8573, 2371, 24668, 1997, 2554, 1005, 1055, 10617, 1997, 2256, 3019, 4219, 1012, 2002, 2387, 1996, 3896, 1997, 2058, 17643, 6774, 1010, 1998, 4265, 1996, 3279, 1997, 2010, 8086, 2229, 2138, 1997, 2009, 1012, 2096, 2116, 2145, 2641, 3019, 4219, 1999, 10288, 13821, 3775, 3468, 1010, 8573, 2052, 4339, 1024, 2057, 2031, 2468, 2307, 2138, 1997, 1996, 22689, 2224, 1997, 2256, 4219, 1012, 2021, 1996, 2051, 2038, 2272, 2000, 1999, 15549, 2890, 5667, 2054, 2097, 4148, 2043, 2256, 6138, 2024, 2908, 1010, 2043, 1996, 5317, 1010, 1996, 3707, 1010, 1996, 3514, 1010, 1998, 1996, 3806, 2024, 9069, 1010, 2043, 1996, 13622, 2031, 2145, 2582, 25488, 1998, 8871, 2046, 1996, 9199, 1010, 8554, 20807, 1996, 5485, 1010, 7939, 24539, 1996, 4249, 1998, 27885, 3367, 6820, 11873, 9163, 1012, 5680, 6233, 2150, 2028, 1997, 8573, 1005, 1055, 2364, 5936, 1012, 2044, 3352, 2343, 1999, 5775, 1010, 8573, 2109, 2010, 3691, 2000, 4047, 6870, 1998, 2270, 4915, 2011, 4526, 1996, 2142, 2163, 3224, 2326, 1006, 2149, 10343, 1007, 1998, 7411, 5018, 2120, 6138, 1010, 4868, 2976, 4743, 8269, 1010, 1018, 2120, 2208, 18536, 1010, 1019, 2120, 6328, 1010, 1998, 2324, 2120, 10490, 2011, 12067, 1996, 5518, 2137, 21387, 2552, 1012, 2076, 2010, 8798, 1010, 10117, 8573, 5123, 3155, 11816, 2454, 4631, 1997, 2270, 2455, 1012, 2651, 1010, 1996, 8027, 1997, 10117, 8573, 2003, 2179, 2408, 1996, 2406, 1012, 2045, 2024, 2416, 2120, 2380, 4573, 4056, 1010, 1999, 2112, 2030, 2878, 1010, 2000, 2256, 5680, 2923, 2343, 1012, 2017, 2064, 2424, 2062, 2592, 2055, 2122, 3182, 2104, 10117, 8573, 3141, 11744, 1012, 2270, 4915, 2511, 2011, 10117, 8573, 1996, 5680, 8027, 1997, 10117, 8573, 2003, 2179, 1999, 1996, 11816, 2454, 4631, 1997, 2270, 4915, 2002, 3271, 5323, 2076, 2010, 8798, 1012, 2172, 1997, 2008, 2455, 1011, 5018, 8817, 4631, 1011, 2001, 2275, 4998, 2004, 2120, 6138, 1012, 8573, 2580, 1996, 2556, 1011, 2154, 2149, 10343, 1999, 5497, 1010, 2019, 3029, 2306, 1996, 2533, 1997, 5237, 1012, 1996, 2801, 2001, 2000, 27749, 6138, 2005, 2506, 2224, 1012, 2019, 29502, 22488, 1997, 16911, 1996, 2406, 1005, 1055, 4219, 1010, 8573, 2359, 2000, 16021, 5397, 1996, 15169, 1997, 2216, 4219, 1012, 8573, 2001, 2036, 1996, 2034, 2343, 2000, 3443, 1037, 2976, 4743, 3914, 1010, 1998, 2002, 2052, 5323, 4868, 1997, 2122, 2076, 2010, 3447, 1012, 2122, 8269, 2052, 2101, 2468, 2651, 1005, 1055, 2120, 6870, 9277, 2015, 1010, 3266, 2011, 1996, 2142, 2163, 3869, 1998, 6870, 2326, 1006, 2149, 2546, 9333, 1007, 1012, 2651, 2045, 2003, 1037, 2120, 6870, 9277, 1999, 2296, 2110, 1010, 1998, 2167, 7734, 21979, 1996, 2087, 9277, 2015, 1997, 2151, 2110, 1999, 1996, 2406, 1012, 2076, 8573, 1005, 1055, 3447, 1010, 1996, 2120, 2380, 2291, 3473, 12381, 1012, 2043, 1996, 2120, 2380, 2326, 2001, 2580, 1999, 4947, 1011, 2698, 2086, 2044, 8573, 2187, 2436, 1011, 2045, 2020, 3486, 4573, 2000, 2022, 3266, 2011, 1996, 2047, 3029, 1012, 8573, 3271, 2580, 2603, 1997, 2216, 1012, 2156, 2917, 2005, 1037, 2862, 1997, 1996, 4573, 2580, 2076, 2010, 3447, 2029, 2024, 4198, 2007, 1996, 2120, 2380, 2326, 1012, 2120, 6328, 2120, 6328, 2024, 2580, 2011, 2019, 2552, 1997, 3519, 1012, 2077, 4947, 1010, 2027, 2020, 3266, 2011, 1996, 3187, 1997, 1996, 4592, 1012, 8573, 2499, 2007, 2010, 4884, 3589, 2000, 5323, 2122, 4573, 1024, 11351, 2697, 2120, 2380, 1006, 2030, 1007, 1011, 5774, 11101, 5430, 2120, 2380, 1006, 17371, 1007, 1011, 5778, 23722, 2135, 2015, 2940, 1006, 1050, 2094, 1007, 1011, 5692, 1006, 2085, 3266, 2011, 2149, 2546, 9333, 1007, 28005, 2120, 2380, 1006, 7929, 1007, 1011, 5518, 1006, 2085, 2112, 1997, 14556, 16782, 2860, 2120, 8640, 2181, 1007, 15797, 16184, 2120, 2380, 1006, 2522, 1007, 1011, 5518, 4215, 5732, 2455, 2000, 10930, 3366, 23419, 2120, 2380, 1006, 6187, 1007, 2120, 10490, 8573, 2772, 1996, 2552, 2005, 1996, 8347, 1997, 2137, 21387, 1011, 2036, 2124, 2004, 1996, 21387, 2552, 2030, 1996, 2120, 10490, 2552, 1011, 2006, 2238, 1022, 1010, 5518, 1012, 1996, 2375, 2435, 1996, 2343, 19258, 2000, 1000, 1000, 13520, 2011, 2270, 16413, 3181, 16209, 1010, 3181, 1998, 14491, 5090, 1010, 1998, 2060, 5200, 1997, 3181, 1998, 4045, 3037, 1012, 1012, 1012, 2000, 2022, 2120, 10490, 1012, 1000, 1000, 2144, 2002, 2106, 2025, 2342, 7740, 6226, 1010, 8573, 2071, 5323, 2120, 10490, 2172, 6082, 2084, 2120, 6328, 1012, 2002, 4056, 2122, 4573, 2004, 2120, 10490, 1024, 6548, 1005, 1055, 3578, 1006, 1059, 2100, 1007, 1011, 5518, 2884, 22822, 3217, 1006, 13221, 1007, 1011, 5518, 9629, 9351, 12248, 3317, 1006, 17207, 1007, 1011, 5518, 22327, 22618, 3224, 1006, 17207, 1007, 1011, 5518, 1006, 2085, 1037, 2120, 2380, 1007, 15775, 3597, 8399, 1006, 13221, 1007, 1011, 5528, 27102, 2368, 4672, 1006, 6187, 1007, 1011, 5528, 1006, 2085, 27333, 2368, 10942, 2120, 2380, 1007, 29399, 13171, 1006, 6187, 1007, 1011, 5528, 1006, 2085, 2112, 1997, 27333, 2368, 10942, 2120, 2380, 1007, 13097, 2050, 7656, 16707, 1006, 13221, 1007, 1011, 5528, 2669, 3406, 1006, 17207, 1007, 1011, 5528, 12274, 4313, 5249, 1006, 6187, 1007, 1011, 5316, 17643, 4859, 8399, 1006, 17207, 1007, 1011, 5316, 1006, 2085, 1037, 2120, 2380, 1007, 26007, 2015, 1006, 6187, 1007, 1011, 5316, 1006, 2085, 1037, 2120, 2380, 1007, 13713, 5430, 1006, 17371, 1007, 1011, 5316, 19833, 11137, 7346, 1006, 21183, 1007, 1011, 5316, 2571, 9148, 2015, 1004, 5215, 16679, 2015, 1006, 11047, 1007, 1011, 5316, 1006, 2085, 1037, 8124, 2110, 2380, 1007, 10722, 22911, 22684, 3089, 1006, 17207, 1007, 1011, 5316, 22920, 2121, 1006, 2522, 1007, 1011, 5316, 1006, 2085, 12819, 22125, 2181, 1010, 2112, 1997, 5673, 9026, 2120, 3224, 1007, 4057, 26742, 1006, 11333, 1007, 1011, 5556, 1006, 2085, 4386, 2120, 2380, 1007, 8573, 2036, 2511, 15775, 13728, 7585, 6104, 1998, 5286, 1999, 5528, 1010, 1037, 2609, 1997, 1996, 2645, 1997, 2047, 5979, 1012, 2009, 2003, 2085, 1037, 2112, 1997, 3744, 2474, 8873, 4674, 2120, 3439, 2380, 1012, 8573, 7896, 2006, 5680, 10117, 8573, 2001, 1996, 2034, 2343, 1997, 1996, 16430, 1010, 1037, 2051, 1997, 2307, 4935, 1998, 2458, 1012, 2010, 13347, 2000, 9530, 8043, 6455, 2256, 3019, 1998, 3451, 2381, 3271, 5323, 1037, 20056, 2012, 2019, 2590, 2051, 1999, 2256, 3842, 1005, 1055, 2381, 1012, 2043, 2116, 2145, 2641, 2256, 4219, 1999, 10288, 13821, 3775, 3468, 1010, 8573, 2387, 2068, 2004, 2242, 2000, 4047, 1998, 24188, 4509, 1024, 2009, 2003, 2036, 3158, 9305, 2964, 2215, 2239, 2135, 2000, 6033, 2030, 2000, 9146, 1996, 6215, 1997, 2054, 2003, 3376, 1999, 3267, 1010, 3251, 2009, 2022, 1037, 7656, 1010, 1037, 3224, 1010, 2030, 1037, 2427, 1997, 25476, 2030, 4743, 1012, 2182, 1999, 1996, 2142, 2163, 2057, 2735, 2256, 5485, 1998, 9199, 2046, 22365, 2015, 1998, 23642, 1011, 5286, 1010, 2057, 8554, 10421, 1996, 2250, 1010, 2057, 6033, 6138, 1010, 1998, 4654, 3334, 19269, 21995, 1010, 5055, 1998, 11993, 1011, 1011, 2025, 2000, 3713, 1997, 29364, 6026, 11951, 12793, 2007, 22293, 14389, 1012, 2021, 2012, 2197, 2009, 3504, 2004, 2065, 2256, 2111, 2020, 16936, 1012, 1996, 2307, 8347, 2923, 2198, 23110, 1010, 4986, 2058, 1996, 6215, 1997, 2530, 2752, 1010, 4778, 2343, 8573, 2000, 3409, 1999, 10930, 3366, 23419, 2120, 2380, 1012, 2044, 2010, 4440, 1010, 8573, 10783, 1024, 1000, 1000, 2009, 2001, 2066, 4688, 1999, 1037, 2307, 19487, 5040, 1010, 2521, 6565, 2121, 1998, 2062, 3376, 2084, 2151, 2328, 2011, 1996, 2192, 1997, 2158, 1012, 1000, 1000, 2002, 3024, 1037, 4675, 1011, 5703, 2000, 2216, 2040, 4912, 2000, 18077, 1996, 3019, 2088, 2005, 3167, 5114, 1012, 2043, 3519, 4061, 2010, 4073, 2000, 3443, 1037, 2120, 2380, 2012, 1996, 2882, 8399, 1010, 8573, 2109, 2010, 3237, 2373, 2000, 4047, 2009, 2004, 1037, 2120, 6104, 1024, 1999, 1996, 2882, 8399, 1010, 5334, 2038, 1037, 3019, 4687, 2029, 2003, 1999, 2785, 7078, 4895, 28689, 6216, 3709, 2802, 1996, 2717, 1997, 1996, 2088, 1012, 1045, 2215, 2000, 3198, 2017, 2000, 2562, 2023, 2307, 4687, 1997, 3267, 2004, 2009, 2085, 2003, 1012, 1045, 3246, 2017, 2097, 2025, 2031, 1037, 2311, 1997, 2151, 2785, 1010, 2025, 1037, 2621, 9151, 1010, 1037, 3309, 2030, 2505, 2842, 1010, 2000, 9388, 1996, 6919, 9026, 3126, 1010, 1996, 4942, 17960, 3012, 1010, 1996, 2307, 20334, 1998, 5053, 1997, 1996, 8399, 1012, 2681, 2009, 2004, 2009, 2003, 1012, 2017, 3685, 5335, 2006, 2009, 1012, 1996, 5535, 2031, 2042, 2012, 2147, 2006, 2009, 1010, 1998, 2158, 2064, 2069, 9388, 2009, 1012, 2017, 2064, 3942, 2256, 4037, 2000, 3191, 2062, 1997, 8573, 1005, 1055, 16614, 2006, 3267, 1998, 5680, 1012, 1000] 1594\n"
     ]
    }
   ],
   "source": [
    "doc_bert_tok = model.tokenize(doc_text)\n",
    "print(doc_bert_tok, len(doc_bert_tok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is important to truncate queries and documents ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_bert_tok=query_bert_tok[0:MAX_QUERY_LEN]\n",
    "doc_bert_tok=doc_bert_tok[0:MAX_DOC_LEN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... and pad queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2120, 2380, 2291, 5323, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "from scripts.cedr.data import PAD_CODE\n",
    "\n",
    "query_bert_tok_pad = query_bert_tok + [PAD_CODE] * (MAX_QUERY_LEN - len(query_bert_tok))\n",
    "print(query_bert_tok_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call unsqueeze(0) is required to create a batch dimension (we can have multiple queries & documents batched together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 477)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tok_tensor_pad = torch.LongTensor(query_bert_tok_pad).unsqueeze(0).to(DEVICE_NAME)\n",
    "doc_tok_tensor = torch.LongTensor(doc_bert_tok).unsqueeze(0).to(DEVICE_NAME)\n",
    "len(query_tok_tensor_pad[0]), len(doc_tok_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32]), torch.Size([1, 477]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tok_tensor_pad.shape, doc_tok_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_mask = torch.FloatTensor([1.0] * len(query_bert_tok) + \n",
    "                              [0.] * (MAX_QUERY_LEN - len(query_bert_tok))).unsqueeze(0).to(DEVICE_NAME)\n",
    "doc_mask = torch.ones_like(doc_tok_tensor).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32]), torch.Size([1, 477]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_mask.shape, doc_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_mask, doc_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.8628], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(query_tok_tensor_pad, query_mask, doc_tok_tensor, doc_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
