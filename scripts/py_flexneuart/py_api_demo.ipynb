{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the repo is cloned, all necessary packages are installed, including calling the script:\n",
    "\n",
    "```./install_packages.sh```\n",
    "\n",
    "and the code is compiled:\n",
    "\n",
    "```./build.sh```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing directory to the repo root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leo/SourceTreeGit/FlexNeuART.develop\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading demo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-08 23:57:42--  http://boytsov.info/datasets/flecsneurt-demo-2021-02-08.tar.bz2\n",
      "Resolving boytsov.info (boytsov.info)... 69.60.127.165\n",
      "Connecting to boytsov.info (boytsov.info)|69.60.127.165|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7511061 (7.2M) [application/x-bzip2]\n",
      "Saving to: ‘flecsneurt-demo-2021-02-08.tar.bz2.2’\n",
      "\n",
      "flecsneurt-demo-202 100%[===================>]   7.16M  8.54MB/s    in 0.8s    \n",
      "\n",
      "2021-02-08 23:57:43 (8.54 MB/s) - ‘flecsneurt-demo-2021-02-08.tar.bz2.2’ saved [7511061/7511061]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget boytsov.info/datasets/flecsneurt-demo-2021-02-08.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x collections/squad/\n",
      "x collections/squad/exper_desc/\n",
      "x collections/squad/input_data/\n",
      "x collections/squad/input_data/train_bitext/\n",
      "x collections/squad/input_data/dev1/\n",
      "x collections/squad/input_data/test/\n",
      "x collections/squad/input_data/dev2/\n",
      "x collections/squad/input_data/train/\n",
      "x collections/squad/input_data/train/AnswerFields.jsonl\n",
      "x collections/squad/input_data/train/QuestionFields.jsonl\n",
      "x collections/squad/input_data/train/qrels.txt\n",
      "x collections/squad/input_data/dev2/AnswerFields.jsonl\n",
      "x collections/squad/input_data/dev2/QuestionFields.jsonl\n",
      "x collections/squad/input_data/dev2/qrels.txt\n",
      "x collections/squad/input_data/test/AnswerFields.jsonl\n",
      "x collections/squad/input_data/test/QuestionFields.jsonl\n",
      "x collections/squad/input_data/test/qrels.txt\n",
      "x collections/squad/input_data/dev1/AnswerFields.jsonl\n",
      "x collections/squad/input_data/dev1/QuestionFields.jsonl\n",
      "x collections/squad/input_data/dev1/qrels.txt\n",
      "x collections/squad/input_data/train_bitext/AnswerFields.jsonl\n",
      "x collections/squad/input_data/train_bitext/QuestionFields.jsonl\n",
      "x collections/squad/input_data/train_bitext/qrels.txt\n",
      "x collections/squad/exper_desc/exper_list.json\n",
      "x collections/squad/exper_desc/models/\n",
      "x collections/squad/exper_desc/extractors/\n",
      "x collections/squad/exper_desc/extractors/bm25=text+cosine=text.json\n",
      "x collections/squad/exper_desc/extractors/bm25=text.json\n",
      "x collections/squad/exper_desc/models/oneFeat.model\n"
     ]
    }
   ],
   "source": [
    "# Unpacking it\n",
    "!tar jxvf flecsneurt-demo-2021-02-08.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "==========================================================================\n",
      "Data directory: collections/squad/input_data\n",
      "Index directory: collections/squad/lucene_index\n",
      "Removing previously created index (if exists)\n",
      "==========================================================================\n",
      "Checking data sub-directory: dev1\n",
      "Found indexable data file: dev1/AnswerFields.jsonl\n",
      "Checking data sub-directory: dev2\n",
      "Found indexable data file: dev2/AnswerFields.jsonl\n",
      "Checking data sub-directory: test\n",
      "Found indexable data file: test/AnswerFields.jsonl\n",
      "Checking data sub-directory: train\n",
      "Found indexable data file: train/AnswerFields.jsonl\n",
      "Checking data sub-directory: train_bitext\n",
      "Found indexable data file: train_bitext/AnswerFields.jsonl\n",
      "Found query file: dev1/QuestionFields.jsonl\n",
      "Found query file: dev2/QuestionFields.jsonl\n",
      "Found query file: test/QuestionFields.jsonl\n",
      "Found query file: train/QuestionFields.jsonl\n",
      "Found query file: train_bitext/QuestionFields.jsonl\n",
      "Using the data input file: AnswerFields.jsonl\n",
      "JAVA_OPTS=-Xms8388608k -Xmx14680064k -server\n",
      "Creating a new Lucene index, maximum # of docs to process: 2147483647\n",
      "Input file name: collections/squad/input_data/dev1/AnswerFields.jsonl\n",
      "Indexed 539 docs\n",
      "Input file name: collections/squad/input_data/dev2/AnswerFields.jsonl\n",
      "Indexed 1106 docs\n",
      "Input file name: collections/squad/input_data/test/AnswerFields.jsonl\n",
      "Indexed 3173 docs\n",
      "Input file name: collections/squad/input_data/train/AnswerFields.jsonl\n",
      "Indexed 4302 docs\n",
      "Input file name: collections/squad/input_data/train_bitext/AnswerFields.jsonl\n",
      "Indexed 10000 docs\n",
      "Indexed 20000 docs\n",
      "Indexed 20963 docs\n"
     ]
    }
   ],
   "source": [
    "# Creating a Lucene index\n",
    "!scripts/index/create_lucene_index.sh squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "==========================================================================\n",
      "Data directory:            collections/squad/input_data\n",
      "Forward index directory:   collections/squad/forward_index/\n",
      "Clean old index?:          1\n",
      "Removing previously created index (if exists)\n",
      "Field list definition:     text:parsedText text_unlemm:raw\n",
      "==========================================================================\n",
      "Checking data sub-directory: dev1\n",
      "Found indexable data file: dev1/AnswerFields.jsonl\n",
      "Checking data sub-directory: dev2\n",
      "Found indexable data file: dev2/AnswerFields.jsonl\n",
      "Checking data sub-directory: test\n",
      "Found indexable data file: test/AnswerFields.jsonl\n",
      "Checking data sub-directory: train\n",
      "Found indexable data file: train/AnswerFields.jsonl\n",
      "Checking data sub-directory: train_bitext\n",
      "Found indexable data file: train_bitext/AnswerFields.jsonl\n",
      "Found query file: dev1/QuestionFields.jsonl\n",
      "Found query file: dev2/QuestionFields.jsonl\n",
      "Found query file: test/QuestionFields.jsonl\n",
      "Found query file: train/QuestionFields.jsonl\n",
      "Found query file: train_bitext/QuestionFields.jsonl\n",
      "JAVA_OPTS=-Xms12582912k -Xmx14680064k -server\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Processing field: 'text'\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index storage type: parsedText\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index storage type: mapdb\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Creating a new forward index, maximum # of docs to process: 2147483647\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/dev1/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/dev2/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/test/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/train/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 10000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 20000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/train_bitext/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Final statistics: \n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Number of documents 20963, total number of words 1381723, average reduction due to keeping only unique words 1.278678\n",
      "JAVA_OPTS=-Xms12582912k -Xmx14680064k -server\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Processing field: 'text_unlemm'\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index storage type: raw\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.apps.BuildFwdIndexApp - Forward index storage type: mapdb\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Creating a new forward index, maximum # of docs to process: 2147483647\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/dev1/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/dev2/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/test/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/train/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 10000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Processed 20000 documents\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Finished processing file: collections/squad/input_data/train_bitext/AnswerFields.jsonl\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Final statistics: \n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.fwdindx.ForwardIndex - Number of documents 20963, total number of words 0, average reduction due to keeping only unique words 0.000000\n"
     ]
    }
   ],
   "source": [
    "#!creating a forward index for two fields:\n",
    "# text is a parsed text field\n",
    "# text_raw is a raw text field that keeps the text as is\n",
    "# -clean removes all previous forward indices\n",
    "!scripts/index/create_fwd_index.sh squad mapdb  \\\n",
    "                               \"text:parsedText text_unlemm:raw\" \\\n",
    "                               -clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Java JAR to the class path\n",
    "configure_classpath('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a resource manager\n",
    "resource_manager=create_featextr_resource_manager('collections/squad/forward_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.cand_provider import *\n",
    "# create a candidate provider/generator\n",
    "cand_prov = create_cand_provider(resource_manager, PROVIDER_TYPE_LUCENE, 'collections/squad/lucene_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_TEXT = \"university notre dame student run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1961,\n",
       " [CandidateEntry(doc_id='@4309', score=27.225019454956055),\n",
       "  CandidateEntry(doc_id='@4323', score=27.155115127563477),\n",
       "  CandidateEntry(doc_id='@2608', score=26.603111267089844),\n",
       "  CandidateEntry(doc_id='@4310', score=26.364826202392578),\n",
       "  CandidateEntry(doc_id='@4303', score=26.196977615356445),\n",
       "  CandidateEntry(doc_id='@4350', score=25.074060440063477),\n",
       "  CandidateEntry(doc_id='@4346', score=24.675006866455078),\n",
       "  CandidateEntry(doc_id='@4316', score=24.361064910888672),\n",
       "  CandidateEntry(doc_id='@4336', score=23.92790985107422),\n",
       "  CandidateEntry(doc_id='@4345', score=23.00181007385254),\n",
       "  CandidateEntry(doc_id='@4320', score=22.964710235595703),\n",
       "  CandidateEntry(doc_id='@2607', score=22.55484390258789),\n",
       "  CandidateEntry(doc_id='@4325', score=22.466575622558594),\n",
       "  CandidateEntry(doc_id='@4330', score=21.723785400390625),\n",
       "  CandidateEntry(doc_id='@4348', score=21.596769332885742),\n",
       "  CandidateEntry(doc_id='@4321', score=21.47646713256836),\n",
       "  CandidateEntry(doc_id='@4338', score=21.426464080810547),\n",
       "  CandidateEntry(doc_id='@4307', score=21.014934539794922),\n",
       "  CandidateEntry(doc_id='@2067', score=20.57712745666504),\n",
       "  CandidateEntry(doc_id='@4342', score=20.57712745666504)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_res = run_query(cand_prov, 20, QUERY_TEXT)\n",
    "query_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward index demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.fwd_index import get_forward_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's play with a raw index that keeps ony unparsed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_indx = get_forward_index(resource_manager, 'text_unlemm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the raw flag is set\n",
    "raw_indx.is_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'architecturally school catholic character atop main building gold dome golden statue virgin mary immediately main building facing copper statue christ arms upraised legend venite ad omnes main building basilica sacred heart immediately basilica grotto marian place prayer reflection replica grotto lourdes france virgin mary reputedly appeared saint bernadette soubirous 1858 end main drive direct line connects 3 statues gold dome simple modern stone statue mary'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_indx.get_doc_raw('@4302')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A parsed index has more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_indx = get_forward_index(resource_manager, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is_raw is False\n",
    "parsed_indx.is_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocEntryParsed(word_ids=[1, 470, 480, 549, 770, 848, 857, 867, 1143, 1193, 1291, 1514, 1562, 1597, 1897, 2210, 2425, 2513, 2579, 3171, 3207, 3357, 3806, 3899, 3960, 4056, 4334, 4790, 5881, 6258, 6274, 6629, 6645, 7051, 7557, 8066, 9139, 10063, 11826, 12878, 13240, 16221, 20752, 32578, 32579, 32580, 32581, 32582, 32583], word_qtys=[1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1], word_id_seq=[10063, 1, 6274, 848, 8066, 1291, 1193, 6645, 9139, 3171, 11826, 1143, 4334, 1597, 1291, 1193, 2210, 3899, 11826, 2425, 3806, 32578, 857, 32579, 7051, 13240, 1291, 1193, 4790, 7557, 4056, 1597, 4790, 32580, 6258, 1897, 5881, 16221, 6629, 32580, 32581, 3207, 1143, 4334, 20752, 470, 2579, 32582, 32583, 12878, 1562, 1291, 3357, 867, 770, 2513, 549, 11826, 6645, 9139, 1514, 480, 3960, 11826, 4334], doc_len=65)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_indx.get_doc_parsed('@4302')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('architecturally', WordEntry(word_id=10063, word_freq=11))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's extract the first document word and its info\n",
    "parsed_indx.get_word_by_id(10063), parsed_indx.get_word_entry_by_id(10063)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranker API demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we run two experiments that involve training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete old results if they are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf collections/squad/results/dev1/feat_exper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Running two experiments (you can add ``-no_separate_shell`` to print logs to the screen for debug purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using collection root: collections\n",
      "The number of CPU cores:      8\n",
      "The number of || experiments: 1\n",
      "The number of threads:        8\n",
      "================================================================================\n",
      "Experiment descriptor file:                                 collections/squad/exper_desc/exper_list.json\n",
      "Default test set:                                           dev1\n",
      "Number of parallel experiments:                             1\n",
      "Number of threads in feature extractors/query applications: 8\n",
      "================================================================================\n",
      "Started a process 84128, working dir: collections/squad/results/dev1/feat_exper/bm25=text\n",
      "Process log file: collections/squad/results/dev1/feat_exper/bm25=text/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=84128 finished successfully.\n",
      "Started a process 84187, working dir: collections/squad/results/dev1/feat_exper/bm25=text+cosine=text\n",
      "Process log file: collections/squad/results/dev1/feat_exper/bm25=text+cosine=text/exper.log\n",
      "Waiting for 1 child processes\n",
      "Process with pid=84187 finished successfully.\n",
      "Waiting for 0 child processes\n",
      "================================================================================\n",
      "2 experiments executed\n",
      "0 experiments failed\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "!scripts/exper/run_experiments.sh squad \\\n",
    "    exper_desc/exper_list.json \\\n",
    "    -train_part train \\\n",
    "    -test_part dev1 \\\n",
    "    -test_cand_qty_list 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print results generated by ``trec_eval``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of queries:    2448\r\n",
      "NDCG@10:        0.923700\r\n",
      "NDCG@20:        0.925800\r\n",
      "NDCG@100:       0.928000\r\n",
      "ERR@20:         0.854820\r\n",
      "P20:            0.048500\r\n",
      "MAP:            0.912100\r\n",
      "MRR:            0.912100\r\n",
      "Recall:         0.982026\r\n",
      "GDEVAL NDCG@20: 0.925840\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!cat collections/squad/results/dev1/feat_exper/bm25\\=text+cosine\\=text/rep/out_100.rep "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second, we can use this model to re-rank and evaluate results using Python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A basic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.py_flexneuart.ranker import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.config import QUESTION_FILE_JSON, QREL_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE_NAME='collections/squad/results/dev1/feat_exper/bm25=text+cosine=text/letor/out_squad_train_20.model'\n",
    "FEAT_EXTR_FILE_NAME='collections/squad/exper_desc/extractors/bm25=text+cosine=text.json'\n",
    "QUERY_FILE_NAME=f'collections/squad/input_data/dev1/{QUESTION_FILE_JSON}'\n",
    "QREL_FILE_NAME=f'collections/squad/input_data/dev1/{QREL_FILE}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list of experimental descriptors, which in turn reference descriptors for feature extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"experSubdir\": \"feat_exper/bm25=text\",\r\n",
      "    \"extrType\" : \"exper_desc/extractors/bm25=text.json\",\r\n",
      "    \"testOnly\": 0\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"experSubdir\": \"feat_exper/bm25=text+cosine=text\",\r\n",
      "    \"extrType\" : \"exper_desc/extractors/bm25=text+cosine=text.json\",\r\n",
      "    \"testOnly\": 0\r\n",
      "  }\r\n",
      "]\r\n"
     ]
    }
   ],
   "source": [
    "!cat collections/squad/exper_desc/exper_list.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A (two-feature) feature extractor confguration, which is used in the second experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "\"extractors\" : [\r\n",
      " {\r\n",
      "  \"type\" : \"TFIDFSimilarity\",\r\n",
      "  \"params\" : {\r\n",
      "    \"indexFieldName\" : \"text\",\r\n",
      "    \"similType\" : \"bm25\",\r\n",
      "    \"k1\"        : \"1.2\",\r\n",
      "    \"b\"         : \"0.75\"\r\n",
      "  }\r\n",
      " },\r\n",
      " {\r\n",
      "  \"type\" : \"TFIDFSimilarity\",\r\n",
      "  \"params\" : {\r\n",
      "    \"indexFieldName\" : \"text\",\r\n",
      "    \"similType\" : \"cosine\"\r\n",
      "  }\r\n",
      " }\r\n",
      "]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!cat collections/squad/exper_desc/extractors/bm25=text+cosine=text.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A simple linear model trained to combine feature scores produced by the feature-extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Coordinate Ascent\r\n",
      "## Restart = 10\r\n",
      "## MaxIteration = 50\r\n",
      "## StepBase = 0.05\r\n",
      "## StepScale = 2.0\r\n",
      "## Tolerance = 0.001\r\n",
      "## Regularized = false\r\n",
      "## Slack = 0.001\r\n",
      "1:0.5464353855587661 2:-0.4535646144412339"
     ]
    }
   ],
   "source": [
    "!cat collections/squad/results/dev1/feat_exper/bm25=text+cosine=text/letor/out_squad_train_20.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A toy example where we generate a list of candidates for merely one query (using the candidate provider) and re-rank them (using the re-ranker object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = create_query_dict(query_text=QUERY_TEXT, \n",
    "                               query_id=FAKE_QUERY_ID, field_name=TEXT_FIELD_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = QueryRanker(resource_manager, feat_extr_file_name=FEAT_EXTR_FILE_NAME, model_file_name=MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@4309': 0.47475528548967094,\n",
       " '@4323': 0.5067933451547831,\n",
       " '@2608': 0.4549869297008977,\n",
       " '@4310': 0.4332624225820959,\n",
       " '@4303': 0.48961460832303094,\n",
       " '@4350': 0.36827643790295006,\n",
       " '@4346': 0.4413701458990109,\n",
       " '@4316': 0.4355512672038647,\n",
       " '@4336': 0.3835355648995015,\n",
       " '@4345': 0.3617851826918027,\n",
       " '@4320': 0.4277601854466731,\n",
       " '@2607': 0.3619121883629782,\n",
       " '@4325': 0.3681315865508774,\n",
       " '@4330': 0.3626696414510794,\n",
       " '@4348': 0.3596303010435613,\n",
       " '@4321': 0.37744164995227447,\n",
       " '@4338': 0.3456784985640041,\n",
       " '@4307': 0.39438917386601124,\n",
       " '@2067': 0.4229184488598747,\n",
       " '@4342': 0.4052451627386573}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker.rank_candidates(query_res[1], query_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A comprehensive example where we evaluate **all** queries from `dev1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data_convert.convert_common import *\n",
    "all_queries = readQueries(QUERY_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'DOCNO': '10595',\n",
       "  'text_unlemm': 'beyonce lighter skin color costuming',\n",
       "  'text': 'beyonce lighter skin color costume'},\n",
       " {'DOCNO': '10608',\n",
       "  'text_unlemm': 'exclusion social political groups targets genocide cppcg legal',\n",
       "  'text': 'exclusion social political group target genocide cppcg legal'},\n",
       " {'DOCNO': '10575',\n",
       "  'text_unlemm': 'beyonce giselle knowles-carter',\n",
       "  'text': 'beyonce giselle knowles-carter'},\n",
       " {'DOCNO': '10570',\n",
       "  'text_unlemm': 'school architecture',\n",
       "  'text': 'school architecture'},\n",
       " {'DOCNO': '10576',\n",
       "  'text_unlemm': 'bee-yon-say born september 4 1981 american',\n",
       "  'text': 'bee-yon-say bear september 4 1981 american'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query sample\n",
    "all_queries[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2448/2448 [00:18<00:00, 135.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "TOP_K=100\n",
    "\n",
    "run_dict = {}\n",
    "for query_dict in tqdm(all_queries):\n",
    "    qid = query_dict[DOCID_FIELD]\n",
    "    query_res = run_query(cand_prov, TOP_K, query_dict[TEXT_FIELD_NAME])\n",
    "    rank_res = ranker.rank_candidates(query_res[1], query_dict)\n",
    "    run_dict[qid] = rank_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, let us compute various metrics using our Python code. Note that results should match results previously produced by `trec_eval`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           \r"
     ]
    }
   ],
   "source": [
    "from scripts.common_eval import *\n",
    "qrels=readQrelsDict(QREL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9236950321010553\n",
      "0.9258372608440565\n",
      "0.9120987070833969\n",
      "0.9120987070833969\n"
     ]
    }
   ],
   "source": [
    "for eval_obj in [NormalizedDiscountedCumulativeGain(10), \\\n",
    "                 NormalizedDiscountedCumulativeGain(20), \\\n",
    "                 MeanAveragePrecision(), \\\n",
    "                 MeanReciprocalRank()]:\n",
    "    print(evalRun(rerankRun=run_dict, metricFunc=eval_obj, qrelsDict=qrels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optionally we can save the run to be later evaluated using external evaluation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeRunDict(run_dict, 'run.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10595 Q0 @2069 1 0.5034178698142255 fake_run\r\n",
      "10595 Q0 @17442 2 0.19901719649322208 fake_run\r\n",
      "10595 Q0 @9111 3 0.19225397364078217 fake_run\r\n",
      "10595 Q0 @1769 4 0.19119073815505058 fake_run\r\n",
      "10595 Q0 @2228 5 0.19033063864976146 fake_run\r\n",
      "10595 Q0 @8585 6 0.18989114401672533 fake_run\r\n",
      "10595 Q0 @18222 7 0.18815638945124924 fake_run\r\n",
      "10595 Q0 @9121 8 0.1853920865272263 fake_run\r\n",
      "10595 Q0 @18223 9 0.18299288131025784 fake_run\r\n",
      "10595 Q0 @9120 10 0.1778561648387402 fake_run\r\n"
     ]
    }
   ],
   "source": [
    "!head run.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
