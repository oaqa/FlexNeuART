{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION='wikipedia_dpr_nq_sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_ROOT='/home/leo/flexneuart_collections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexneuart import configure_classpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Java JAR to the class path\n",
    "configure_classpath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexneuart.retrieval import create_featextr_resource_manager\n",
    "\n",
    "# create a resource manager\n",
    "resource_manager=create_featextr_resource_manager(resource_root_dir=f'{COLLECTION_ROOT}/{COLLECTION}/',\n",
    "                                                  fwd_index_dir='forward_index',\n",
    "                                                  model1_root_dir=f'derived_data/giza',\n",
    "                                                  embed_root_dir=f'derived_data/embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flexneuart\n",
    "flexneuart.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexneuart.config import QUESTION_FILE_JSON, QREL_FILE, DOCID_FIELD, TEXT_FIELD_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.resources.ResourceManager - Provider type: lucene\n",
      "URI: lucene_index\n",
      "Config file: none\n",
      "# of threads: 1\n",
      "[main] INFO edu.cmu.lti.oaqa.flexneuart.cand_providers.LuceneCandidateProvider - Lucene candidate provider k1=1.20000, b=0.750000 query field name: text index field name: text Exact field match?: false\n"
     ]
    }
   ],
   "source": [
    "from flexneuart.retrieval.cand_provider import *\n",
    "# create a candidate provider/generator\n",
    "cand_prov = create_cand_provider(resource_manager, PROVIDER_TYPE_LUCENE, f'lucene_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_TEXT = \"vein carry blood heart away\"\n",
    "QUERY_TEXT_BERT_TOK = \"do veins carry blood to the heart or away\"\n",
    "QUTE_TEXT_UNLEMM = \"veins carry blood heart away\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1329,\n",
       " [CandidateEntry(doc_id='639661', score=18.328275680541992),\n",
       "  CandidateEntry(doc_id='472789', score=16.816619873046875),\n",
       "  CandidateEntry(doc_id='1776205', score=16.630727767944336),\n",
       "  CandidateEntry(doc_id='639669', score=15.6367826461792),\n",
       "  CandidateEntry(doc_id='8448903', score=15.448601722717285),\n",
       "  CandidateEntry(doc_id='8448902', score=15.369601249694824),\n",
       "  CandidateEntry(doc_id='639670', score=15.27547550201416),\n",
       "  CandidateEntry(doc_id='639663', score=14.904623985290527),\n",
       "  CandidateEntry(doc_id='35722', score=14.59425163269043),\n",
       "  CandidateEntry(doc_id='1302853', score=14.318553924560547),\n",
       "  CandidateEntry(doc_id='639671', score=14.157160758972168),\n",
       "  CandidateEntry(doc_id='1786523', score=14.077558517456055),\n",
       "  CandidateEntry(doc_id='588394', score=13.997241973876953),\n",
       "  CandidateEntry(doc_id='639690', score=13.810718536376953),\n",
       "  CandidateEntry(doc_id='1450640', score=13.643953323364258),\n",
       "  CandidateEntry(doc_id='3936360', score=13.642525672912598),\n",
       "  CandidateEntry(doc_id='5622935', score=13.536111831665039),\n",
       "  CandidateEntry(doc_id='2992576', score=13.500545501708984),\n",
       "  CandidateEntry(doc_id='47133', score=13.166474342346191),\n",
       "  CandidateEntry(doc_id='47129', score=13.15163803100586)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of running a text query\n",
    "query_res = run_text_query(cand_prov, 20, QUERY_TEXT)\n",
    "query_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1329,\n",
       " [CandidateEntry(doc_id='639661', score=18.328275680541992),\n",
       "  CandidateEntry(doc_id='472789', score=16.816619873046875),\n",
       "  CandidateEntry(doc_id='1776205', score=16.630727767944336),\n",
       "  CandidateEntry(doc_id='639669', score=15.6367826461792),\n",
       "  CandidateEntry(doc_id='8448903', score=15.448601722717285),\n",
       "  CandidateEntry(doc_id='8448902', score=15.369601249694824),\n",
       "  CandidateEntry(doc_id='639670', score=15.27547550201416),\n",
       "  CandidateEntry(doc_id='639663', score=14.904623985290527),\n",
       "  CandidateEntry(doc_id='35722', score=14.59425163269043),\n",
       "  CandidateEntry(doc_id='1302853', score=14.318553924560547),\n",
       "  CandidateEntry(doc_id='639671', score=14.157160758972168),\n",
       "  CandidateEntry(doc_id='1786523', score=14.077558517456055),\n",
       "  CandidateEntry(doc_id='588394', score=13.997241973876953),\n",
       "  CandidateEntry(doc_id='639690', score=13.810718536376953),\n",
       "  CandidateEntry(doc_id='1450640', score=13.643953323364258),\n",
       "  CandidateEntry(doc_id='3936360', score=13.642525672912598),\n",
       "  CandidateEntry(doc_id='5622935', score=13.536111831665039),\n",
       "  CandidateEntry(doc_id='2992576', score=13.500545501708984),\n",
       "  CandidateEntry(doc_id='47133', score=13.166474342346191),\n",
       "  CandidateEntry(doc_id='47129', score=13.15163803100586)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of running a generic query interface\n",
    "query_res = run_query(cand_prov, 20, {TEXT_FIELD_NAME : QUERY_TEXT}, default_query_id=FAKE_QUERY_ID)\n",
    "query_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1329,\n",
       " [CandidateEntry(doc_id='639661', score=18.328275680541992),\n",
       "  CandidateEntry(doc_id='472789', score=16.816619873046875),\n",
       "  CandidateEntry(doc_id='1776205', score=16.630727767944336),\n",
       "  CandidateEntry(doc_id='639669', score=15.6367826461792),\n",
       "  CandidateEntry(doc_id='8448903', score=15.448601722717285),\n",
       "  CandidateEntry(doc_id='8448902', score=15.369601249694824),\n",
       "  CandidateEntry(doc_id='639670', score=15.27547550201416),\n",
       "  CandidateEntry(doc_id='639663', score=14.904623985290527),\n",
       "  CandidateEntry(doc_id='35722', score=14.59425163269043),\n",
       "  CandidateEntry(doc_id='1302853', score=14.318553924560547),\n",
       "  CandidateEntry(doc_id='639671', score=14.157160758972168),\n",
       "  CandidateEntry(doc_id='1786523', score=14.077558517456055),\n",
       "  CandidateEntry(doc_id='588394', score=13.997241973876953),\n",
       "  CandidateEntry(doc_id='639690', score=13.810718536376953),\n",
       "  CandidateEntry(doc_id='1450640', score=13.643953323364258),\n",
       "  CandidateEntry(doc_id='3936360', score=13.642525672912598),\n",
       "  CandidateEntry(doc_id='5622935', score=13.536111831665039),\n",
       "  CandidateEntry(doc_id='2992576', score=13.500545501708984),\n",
       "  CandidateEntry(doc_id='47133', score=13.166474342346191),\n",
       "  CandidateEntry(doc_id='47129', score=13.15163803100586)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of running a generic query interface\n",
    "query_res = run_query(cand_prov, 20, {DOCID_FIELD: FAKE_QUERY_ID, TEXT_FIELD_NAME : QUERY_TEXT})\n",
    "query_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward index demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flexneuart.retrieval.fwd_index import get_forward_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's play with a raw index that keeps ony unparsed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_indx = get_forward_index(resource_manager, 'text_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'textRaw'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index type\n",
    "raw_indx.indx_fld_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vein \"Vein Veins are blood vessels that carry blood toward the heart. Most veins carry deoxygenated blood from the tissues back to the heart; exceptions are the pulmonary and umbilical veins, both of which carry oxygenated blood to the heart. In contrast to veins, arteries carry blood away from the heart. Veins are less muscular than arteries and are often closer to the skin. There are valves in most veins to prevent backflow. Veins are present throughout the body as tubes that carry blood back to the heart. Veins are classified in a number of ways, including superficial vs. deep, pulmonary\"'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_indx.get_doc_text_raw('639661')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A parsed index has more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_indx = get_forward_index(resource_manager, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'parsedText'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index type\n",
    "parsed_indx.indx_fld_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocEntryParsed(word_ids=[75, 144, 210, 246, 506, 587, 589, 591, 594, 867, 1268, 1282, 2311, 2516, 3125, 3352, 4121, 5121, 7795, 8410, 8455, 12461, 14717, 14722, 14724, 23655, 23669, 27261, 59794, 102036], word_qtys=[1, 1, 5, 1, 5, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 9, 6, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1], word_id_seq=[7795, 7795, 102036, 8410, 5121, 506, 8410, 210, 7795, 506, 23655, 8410, 587, 2311, 210, 14724, 23669, 7795, 506, 14717, 8410, 210, 4121, 7795, 8455, 506, 8410, 3125, 210, 7795, 27261, 8455, 246, 589, 14722, 7795, 1282, 59794, 7795, 1268, 75, 2516, 506, 8410, 2311, 210, 7795, 3352, 144, 867, 591, 12461, 594, 14724], doc_len=54)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_indx.get_doc_parsed('639661')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('body', WordEntry(word_id=75, word_freq=17735))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's extract the first document word and its info\n",
    "parsed_indx.get_word_by_id(75), parsed_indx.get_word_entry_by_id(75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranker API demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load the NDRM models (which require additional libraries): No module named 'fasttext'\n"
     ]
    }
   ],
   "source": [
    "from flexneuart.ranker.neural import *\n",
    "from flexneuart.ranker.classic import *\n",
    "from flexneuart.io.queries import *\n",
    "from flexneuart.io.qrels import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model files and feature extractor configuration is relative to the collection (resource root) directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BM25_MODEL1_FILE_NAME='exper_desc.best/models/bm25_model1.model'\n",
    "FEAT_EXTR_BM25_MODEL1_FILE_NAME='exper_desc.best/extractors/bm25=text+model1=text_bert_tok+lambda=0.3+probSelfTran=0.35.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, we load queries using a full path or relative path that includes collection directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_FILE_NAME=f'{COLLECTION_ROOT}/{COLLECTION}/input_data/dev/{QUESTION_FILE_JSON}'\n",
    "QREL_FILE_NAME=f'{COLLECTION_ROOT}/{COLLECTION}/input_data/dev/{QREL_FILE}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A toy example where we generate a list of candidates for merely one query (using the candidate provider) and re-rank them using the Java-layer re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_ranker_bm25_model1 = ClassicRanker(resource_manager, \n",
    "                              feat_extr_file_name=FEAT_EXTR_BM25_MODEL1_FILE_NAME, \n",
    "                              model_file_name=MODEL_BM25_MODEL1_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('639661', 3.110925911937358),\n",
       " ('472789', 2.899738798467234),\n",
       " ('1776205', 2.805803609295945),\n",
       " ('639669', 2.7800462122473557),\n",
       " ('8448903', 2.7269659839801665),\n",
       " ('35722', 2.710448890456231),\n",
       " ('8448902', 2.7087988053702823),\n",
       " ('639670', 2.5747502244230036),\n",
       " ('47133', 2.5242492838996617),\n",
       " ('1302853', 2.5076294275554907),\n",
       " ('5622935', 2.4809257731039933),\n",
       " ('47129', 2.469478684784585),\n",
       " ('639671', 2.4472600960890074),\n",
       " ('2992576', 2.441949382525879),\n",
       " ('588394', 2.4208285769287112),\n",
       " ('1450640', 2.4162580827133944),\n",
       " ('639690', 2.336798310942606),\n",
       " ('3936360', 2.294797693585073),\n",
       " ('639663', 2.2836513715212163),\n",
       " ('1786523', 2.1695004812280785)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_dict = {DOCID_FIELD : FAKE_QUERY_ID,\n",
    "              'text_bert_tok': QUERY_TEXT_BERT_TOK,\n",
    "              'text_unlemm': QUTE_TEXT_UNLEMM,\n",
    "              TEXT_FIELD_NAME : QUERY_TEXT}\n",
    "java_ranker_bm25_model1.rank_candidates(query_res[1], query_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There's a function (used only for evaluation) to score candidates without sorting them scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'639661': 3.110925911937358,\n",
       " '472789': 2.899738798467234,\n",
       " '1776205': 2.805803609295945,\n",
       " '639669': 2.7800462122473557,\n",
       " '8448903': 2.7269659839801665,\n",
       " '8448902': 2.7087988053702823,\n",
       " '639670': 2.5747502244230036,\n",
       " '639663': 2.2836513715212163,\n",
       " '35722': 2.710448890456231,\n",
       " '1302853': 2.5076294275554907,\n",
       " '639671': 2.4472600960890074,\n",
       " '1786523': 2.1695004812280785,\n",
       " '588394': 2.4208285769287112,\n",
       " '639690': 2.336798310942606,\n",
       " '1450640': 2.4162580827133944,\n",
       " '3936360': 2.294797693585073,\n",
       " '5622935': 2.4809257731039933,\n",
       " '2992576': 2.441949382525879,\n",
       " '47133': 2.5242492838996617,\n",
       " '47129': 2.469478684784585}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java_ranker_bm25_model1.score_candidates(query_res[1], query_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example of a classic BM25 reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BM25_FILE_NAME='exper_desc.best/models/one_feat.model'\n",
    "FEAT_EXTR_BM25_FILE_NAME='exper_desc.best/extractors/bm25.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\t\tCoordinate Ascent\n"
     ]
    }
   ],
   "source": [
    "java_ranker_bm25 = ClassicRanker(resource_manager, \n",
    "                              feat_extr_file_name=FEAT_EXTR_BM25_FILE_NAME, \n",
    "                              model_file_name=MODEL_BM25_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'639661': 1.3841341733932495,\n",
       " '472789': 1.304264783859253,\n",
       " '1776205': 1.3092241287231445,\n",
       " '639669': 1.1689906120300293,\n",
       " '8448903': 1.2439945936203003,\n",
       " '8448902': 1.240858793258667,\n",
       " '639670': 1.1532176733016968,\n",
       " '639663': 1.1385170221328735,\n",
       " '35722': 1.204897165298462,\n",
       " '1302853': 1.106221318244934,\n",
       " '639671': 1.0966399908065796,\n",
       " '1786523': 1.093814492225647,\n",
       " '588394': 1.1547898054122925,\n",
       " '639690': 1.1017565727233887,\n",
       " '1450640': 1.1577613353729248,\n",
       " '3936360': 1.1655044555664062,\n",
       " '5622935': 1.0610493421554565,\n",
       " '2992576': 1.066516399383545,\n",
       " '47133': 1.1253129243850708,\n",
       " '47129': 1.0485056638717651}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java_ranker_bm25.score_candidates(query_res[1], query_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  A an example of a ranker that uses averaged embeddings (loading embeddings can take a couple of minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_ranker_avg_embed = ClassicRanker(resource_manager, \n",
    "                                          feat_extr_file_name='exper_desc.best/extractors/avgembed.json', \n",
    "                                          model_file_name='exper_desc.best/models/one_feat.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'639661': 0.9558641314506531,\n",
       " '472789': 0.9116753935813904,\n",
       " '1776205': 0.9183375835418701,\n",
       " '639669': 0.9491961002349854,\n",
       " '8448903': 0.8954006433486938,\n",
       " '8448902': 0.8910415172576904,\n",
       " '639670': 0.8910543322563171,\n",
       " '639663': 0.8869085311889648,\n",
       " '35722': 0.8330867886543274,\n",
       " '1302853': 0.8790420889854431,\n",
       " '639671': 0.8644178509712219,\n",
       " '1786523': 0.8477801084518433,\n",
       " '588394': 0.9045305848121643,\n",
       " '639690': 0.7475028038024902,\n",
       " '1450640': 0.7521618604660034,\n",
       " '3936360': 0.7771363854408264,\n",
       " '5622935': 0.917460560798645,\n",
       " '2992576': 0.9202541708946228,\n",
       " '47133': 0.7589597105979919,\n",
       " '47129': 0.9198287725448608}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java_ranker_avg_embed.score_candidates(query_res[1], query_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A toy example where we re-rank the list of candidate using a BERT re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type name: vanilla_bert, registered class: <class 'flexneuart.models.cedr.cedr_vanilla_bert.VanillaBertCEDRRanker'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: bert-base-uncased # of channels: 13 hidden layer size: 768 input window size: 512 no token type IDs: False\n",
      "Dropout Dropout(p=0.05, inplace=False)\n"
     ]
    }
   ],
   "source": [
    "# Re-ranking on CPU, which can be fairly slow\n",
    "neural_ranker = NeuralRanker(resource_manager, \n",
    "                         keep_case=False,\n",
    "                         query_field_name='text_raw', \n",
    "                         index_field_name='text_raw', \n",
    "                         device_name='cuda', batch_size=25, \n",
    "                         model_path_rel=f'derived_data/ir_models/vanilla_bert/model.best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('639661', 1.4452017545700073),\n",
       " ('1786523', 0.8732627630233765),\n",
       " ('472789', 0.6902247667312622),\n",
       " ('639663', 0.4931100010871887),\n",
       " ('8448903', 0.395744264125824),\n",
       " ('3936360', 0.12360292673110962),\n",
       " ('35722', 0.06624050438404083),\n",
       " ('639670', -0.0123380646109581),\n",
       " ('639669', -0.0417940728366375),\n",
       " ('1776205', -0.14387202262878418),\n",
       " ('47133', -0.1606408804655075),\n",
       " ('1450640', -0.17226377129554749),\n",
       " ('47129', -0.18515662848949432),\n",
       " ('8448902', -0.24556735157966614),\n",
       " ('639671', -0.28867408633232117),\n",
       " ('639690', -0.5904686450958252),\n",
       " ('1302853', -0.7343864440917969),\n",
       " ('2992576', -0.7898008823394775),\n",
       " ('588394', -0.844143271446228),\n",
       " ('5622935', -1.08793044090271)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_dict = {DOCID_FIELD : FAKE_QUERY_ID, \n",
    "              'text_raw' : QUERY_TEXT}\n",
    "neural_ranker.rank_candidates(query_res[1], query_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'639661': 1.4452017545700073,\n",
       " '472789': 0.6902247667312622,\n",
       " '1776205': -0.14387202262878418,\n",
       " '639669': -0.0417940728366375,\n",
       " '8448903': 0.395744264125824,\n",
       " '8448902': -0.24556735157966614,\n",
       " '639670': -0.0123380646109581,\n",
       " '639663': 0.4931100010871887,\n",
       " '35722': 0.06624050438404083,\n",
       " '1302853': -0.7343864440917969,\n",
       " '639671': -0.28867408633232117,\n",
       " '1786523': 0.8732627630233765,\n",
       " '588394': -0.844143271446228,\n",
       " '639690': -0.5904686450958252,\n",
       " '1450640': -0.17226377129554749,\n",
       " '3936360': 0.12360292673110962,\n",
       " '5622935': -1.08793044090271,\n",
       " '2992576': -0.7898008823394775,\n",
       " '47133': -0.1606408804655075,\n",
       " '47129': -0.18515662848949432}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_dict = {DOCID_FIELD : FAKE_QUERY_ID, \n",
    "              'text_raw' : QUERY_TEXT}\n",
    "neural_ranker.score_candidates(query_res[1], query_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CandidateEntry(doc_id='639661', score=18.328275680541992),\n",
       " CandidateEntry(doc_id='472789', score=16.816619873046875),\n",
       " CandidateEntry(doc_id='1776205', score=16.630727767944336),\n",
       " CandidateEntry(doc_id='639669', score=15.6367826461792),\n",
       " CandidateEntry(doc_id='8448903', score=15.448601722717285),\n",
       " CandidateEntry(doc_id='8448902', score=15.369601249694824),\n",
       " CandidateEntry(doc_id='639670', score=15.27547550201416),\n",
       " CandidateEntry(doc_id='639663', score=14.904623985290527),\n",
       " CandidateEntry(doc_id='35722', score=14.59425163269043),\n",
       " CandidateEntry(doc_id='1302853', score=14.318553924560547),\n",
       " CandidateEntry(doc_id='639671', score=14.157160758972168),\n",
       " CandidateEntry(doc_id='1786523', score=14.077558517456055),\n",
       " CandidateEntry(doc_id='588394', score=13.997241973876953),\n",
       " CandidateEntry(doc_id='639690', score=13.810718536376953),\n",
       " CandidateEntry(doc_id='1450640', score=13.643953323364258),\n",
       " CandidateEntry(doc_id='3936360', score=13.642525672912598),\n",
       " CandidateEntry(doc_id='5622935', score=13.536111831665039),\n",
       " CandidateEntry(doc_id='2992576', score=13.500545501708984),\n",
       " CandidateEntry(doc_id='47133', score=13.166474342346191),\n",
       " CandidateEntry(doc_id='47129', score=13.15163803100586)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_res[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A comprehensive example where we evaluate **all** queries from `dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries = read_queries(QUERY_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'DOCNO': 'dev_0',\n",
       "  'text': 'vein carry blood heart away',\n",
       "  'text_unlemm': 'veins carry blood heart away',\n",
       "  'text_raw': 'do veins carry blood to the heart or away',\n",
       "  'answer_list': ['to'],\n",
       "  'text_bert_tok': 'do veins carry blood to the heart or away'},\n",
       " {'DOCNO': 'dev_1',\n",
       "  'text': 'sister king country',\n",
       "  'text_unlemm': 'sister king country',\n",
       "  'text_raw': 'who is the sister of for king and country',\n",
       "  'answer_list': ['Rebecca St. James'],\n",
       "  'text_bert_tok': 'who is the sister of for king and country'},\n",
       " {'DOCNO': 'dev_2',\n",
       "  'text': 'develop periodic table 8 column',\n",
       "  'text_unlemm': 'developed periodic table 8 columns',\n",
       "  'text_raw': 'who developed the first periodic table with 8 columns',\n",
       "  'answer_list': ['Dmitri Mendeleev'],\n",
       "  'text_bert_tok': 'who developed the first periodic table with 8 columns'},\n",
       " {'DOCNO': 'dev_3',\n",
       "  'text': 'season 14 grey anatomy come',\n",
       "  'text_unlemm': 'season 14 grey anatomy come',\n",
       "  'text_raw': \"when does season 14 of grey 's anatomy come out\",\n",
       "  'answer_list': ['September 28 , 2017'],\n",
       "  'text_bert_tok': \"when does season 14 of grey ' s anatomy come out\"},\n",
       " {'DOCNO': 'dev_4',\n",
       "  'text': 'big statue jesus locate',\n",
       "  'text_unlemm': 'big statue jesus located',\n",
       "  'text_raw': 'where is the big statue of jesus located',\n",
       "  'answer_list': ['Rio de Janeiro , Brazil'],\n",
       "  'text_bert_tok': 'where is the big statue of jesus located'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query sample\n",
    "all_queries[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries have one extra field that cannot be \"digested\" by the ranking API and we need to delete it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:00<00:00, 976145.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for query_dict in tqdm(all_queries):\n",
    "    # Delete this field, it cannot be used by ranker\n",
    "    del query_dict['answer_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:02<00:00, 224.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0.23153725283035664\n",
      "0.2611430435620929\n",
      "0.1882523067559224\n",
      "0.3165160815593989\n",
      "===========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 278.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0.40148726937982154\n",
      "0.43277089120056567\n",
      "0.33493535080832154\n",
      "0.5009406767385571\n",
      "===========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:02<00:00, 184.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0.4640738457712773\n",
      "0.4924966820985511\n",
      "0.3838658604949658\n",
      "0.5713954663360119\n",
      "===========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 500/500 [03:08<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0.5694050471419018\n",
      "0.581268005015674\n",
      "0.481329427613784\n",
      "0.6842795695923616\n",
      "===========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from flexneuart.eval import *\n",
    "from flexneuart.utils import sync_out_streams\n",
    "from tqdm import tqdm\n",
    "\n",
    "TOP_K=50\n",
    "MAX_QUERIES_QTY=500\n",
    "qrels=read_qrels_dict(QREL_FILE_NAME)\n",
    "\n",
    "for ranker in [java_ranker_avg_embed, java_ranker_bm25, java_ranker_bm25_model1, neural_ranker]:\n",
    "    run_dict = {}\n",
    "    with tqdm(all_queries[0:MAX_QUERIES_QTY]) as pbar:\n",
    "        for query_dict in pbar:\n",
    "            qid = query_dict[DOCID_FIELD]\n",
    "            query_res = run_query(cand_prov, TOP_K, query_dict)\n",
    "            rank_res = ranker.score_candidates(query_res[1], query_dict)\n",
    "            run_dict[qid] = rank_res\n",
    "    tqdm.write('\\n')\n",
    "        \n",
    "    # Let us compute various metrics using our Python code. \n",
    "    # Note that results should generally match results obtained using `scripts/exper/run_experiments.sh`\n",
    "    for eval_obj in [NormalizedDiscountedCumulativeGain(10), \\\n",
    "                 NormalizedDiscountedCumulativeGain(20), \\\n",
    "                 MeanAveragePrecision(), \\\n",
    "                 MeanReciprocalRank()]:\n",
    "        tqdm.write(str(internal_eval(run=run_dict, metric_func=eval_obj, qrels=qrels)[0]))\n",
    "    \n",
    "    tqdm.write('==========================='+ '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optionally we can save the run to be later evaluated using external evaluation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_run_dict(run_dict, 'run.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "dev_0 Q0 639661 1 2.028193950653076 fake_run\n",
      "dev_0 Q0 35722 2 1.4752246141433716 fake_run\n",
      "dev_0 Q0 472789 3 1.355614185333252 fake_run\n",
      "dev_0 Q0 8448902 4 1.24833345413208 fake_run\n",
      "dev_0 Q0 588391 5 1.1973053216934204 fake_run\n",
      "dev_0 Q0 8448903 6 1.1692496538162231 fake_run\n",
      "dev_0 Q0 588392 7 0.9428008794784546 fake_run\n",
      "dev_0 Q0 639663 8 0.9341850280761719 fake_run\n",
      "dev_0 Q0 2981475 9 0.9230215549468994 fake_run\n",
      "dev_0 Q0 1786523 10 0.8120793104171753 fake_run\n"
     ]
    }
   ],
   "source": [
    "!head run.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
